{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de persuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from collections import Counter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26f6dede510>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de GPUs disponibles. Usar 0 para modo CPU.\n",
    "ngpu = 1\n",
    "\n",
    "# Fuente de la cual queremos obtener los datos\n",
    "source = 'corenlp'\n",
    "\n",
    "# Semilla a usar en los generadores de números aleatorios\n",
    "SEED = 72\n",
    "# SEED = random.randint(1, 10000) # En caso de requerir más resultados\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decide si queremos correr en gpu o cpu\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de las Categorías\n",
    "\n",
    "### Categoría Cognitiva\n",
    "\n",
    "#### Subcategoría:\n",
    "\n",
    "1.\t**Construcción del emisor/candidato (C1):** el candidato se coloca como referente principal del acto discursivo para exaltar sus cualidades personales y erigirse, a los ojos de sus interlocutores, como un líder en quien es adecuado confiar para el desarrollo de acciones de gobierno a favor de la sociedad; esto lo lleva a cabo mediante realizaciones léxicas de la primera persona, en singular o plural, y formas flexivas de verbos y posesivos para referirse a sí mismo, ya sea como individuo o como miembro de una colectividad.\n",
    "\n",
    "### Categoría Emocional\n",
    "\n",
    "#### Subcategorías:\n",
    "\n",
    "2.\t**Construcción del adversario (E1):** el mensaje es dirigido a su contraparte en la contienda electoral y está construido a manera de réplica y puede usar diferentes figuras retóricas (metáfora, ironía, metonimia) para conformar en el receptor una imagen determinada del adversario, que esencialmente tiene finalidad de descrédito.\n",
    "3.\t**Exageración de la información (E2):** se destacan los datos favorables a los fines persuasivos, con el objetivo de crear una idea positiva en la mente del receptor referente al tema del que se habla, o incluso negativa respecto de información relativa al adversario; el persuasor desfigura el sentido original del acontecimiento, nos dice Roiz (1994), mediante códigos diferentes: humorístico, burlesco, cínico, entre otros. \n",
    "4.\t**Recurso metafórico (E3):**: son variables metafóricas que pueden fortalecer el efecto persuasivo, de acuerdo con Reardon (1991).\n",
    "5.\t**Apelación al miedo (E4):** el candidato emite mensajes dentro de su alocución que pretenden provocar sentimientos de aprensión, desasosiego o preocupación con respecto al adversario o a sus propuestas. \n",
    "\n",
    "### Categoría Volitiva\n",
    "\n",
    "#### Subcategoría:\n",
    "\n",
    "6.\t**Llamado al voto (V1):** el emisor del mensaje hace una invitación, velada o directa, al ciudadano para que apoye su proyecto político el día de la elección al depositar el sufragio a su favor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1': 0, 'E1': 1, 'E2': 2, 'E3': 3, 'E4': 4, 'V1': 5}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_cat = ['C1', 'E1', 'E2', 'E3', 'E4','V1']\n",
    "cat_to_ix = { cat: ix for ix, cat in enumerate(ix_to_cat) }\n",
    "\n",
    "num_cat = len(ix_to_cat) # Tamaño de salida de la red\n",
    "\n",
    "cat_to_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', 'de', 'que', 'la', 'a']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_w = []\n",
    "with open(f'./../Embeddings/word_labels_{source}.txt', 'r', encoding='utf-8') as f:\n",
    "    ix_to_w = f.read().splitlines()\n",
    "    \n",
    "w_to_ix = { w: ix for ix, w in enumerate(ix_to_w) }\n",
    "\n",
    "tam_vocab = len(ix_to_w)\n",
    "\n",
    "ix_to_w[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enunciados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El candidato de la coalición Todos por México se comprometió a estar con la población guerrerense en las buenas y en las malas .',\n",
       " 'Respecto a las zonas económicas especiales , el candidato de la coalición Todos por México mencionó que éstas deben ser aprovechadas como una especie de laboratorio , que genere recimiento a la medida en el norte y en el sur de la República mexicana .',\n",
       " 'Se compromete a abrir escuelas y guarderías de tiempo completo .',\n",
       " '\" Aquí están las mujeres y hombres priistas que son todo terreno , los que van a hacer posible que Pepe Meade sea presidente ; un hombre preparado , capaz y con experiencia para enfrentar la gobernabilidad de un país como México .',\n",
       " 'Y , quinto , Fiscalías General y Anticorrupción absolutamente autónomas e independientes , que puedan juzgar y perseguir a cualquier funcionario , incluyendo a el Presidente de la República .']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "with open(f'./Corpus/Train/sentences-{source}.txt', 'r', encoding='utf-8') as f:\n",
    "    sentences = [s.split() for s in f.read().splitlines()]\n",
    "\n",
    "{[' '.join(s) for s in sentences[:5]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorías persuasivas por enunciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NA']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_sents = []\n",
    "with open('./Corpus/Train/sentences-tags.txt', 'r', encoding='utf-8') as f:\n",
    "    categorias_sents = [t.split() for t in f.read().splitlines()]\n",
    "\n",
    "categorias_sents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar datos para Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "ixBOS = w_to_ix[BOS]\n",
    "ixEOS = w_to_ix[EOS]\n",
    "ixUNK = w_to_ix[UNK]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palabras a índices numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unk_w_to_ix(w):\n",
    "    try:\n",
    "        return w_to_ix[w]\n",
    "    except KeyError:\n",
    "        return ixUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[5, 26, 1, 3, 38, 33, 16, 20, 11, 203, 4, 249, 14, 3, 441, 7473, 8, 17, 1972, 7, 8, 17, 1929, 6]',\n",
       " '[1416, 4, 17, 1183, 3052, 4901, 0, 5, 26, 1, 3, 38, 33, 16, 20, 284, 2, 3056, 909, 89, 7473, 28, 24, 3487, 1, 7473, 0, 2, 2709, 7473, 4, 3, 1098, 8, 5, 563, 7, 8, 5, 668, 1, 3, 71, 645, 6]',\n",
       " '[11, 1237, 4, 2807, 560, 7, 602, 1, 170, 431, 6]',\n",
       " '[10, 195, 70, 17, 114, 7, 540, 881, 2, 57, 66, 1522, 0, 9, 2, 84, 4, 93, 769, 2, 1688, 34, 145, 53, 105, 19, 776, 1943, 0, 2716, 7, 14, 854, 13, 675, 3, 4741, 1, 19, 32, 28, 20, 6]',\n",
       " '[7, 0, 2181, 0, 4940, 383, 7, 2142, 797, 4941, 185, 1968, 0, 2, 541, 3402, 7, 2806, 4, 942, 1466, 0, 2464, 4, 5, 53, 1, 3, 71, 6]']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [\n",
    "    # Convierto las palabras (en minúsculas) a índices\n",
    "    [ unk_w_to_ix(w.lower()) for w in sent ] \n",
    "    for sent in sentences\n",
    "]\n",
    "\n",
    "[str(x) for x in X[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = [[0 for _ in range(6)] for c in categorias_sents]\n",
    "\n",
    "for i, cats_sents in enumerate(categorias_sents):\n",
    "    for cat in cats_sents:\n",
    "        try:\n",
    "            ix_cat = cat_to_ix[cat]\n",
    "            Y[i][ix_cat] = 1 # Pongo 1 si encuentro la categoría\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersuasionLSTM(nn.Module):\n",
    "    def __init__(self, D_in, D_emb, D_lstm, D_out):\n",
    "        super(PersuasionLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb)#, padding_idx=0)\n",
    "        # self.dropout = nn.Dropout(p=0.2)\n",
    "        self.lstm = nn.LSTM(input_size=D_emb, hidden_size=D_lstm)\n",
    "        self.linear = nn.Linear(in_features=D_lstm, out_features=D_out)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, sentence):\n",
    "        T = len(sentence)\n",
    "        embeddings = self.embedding(sentence).view(T, 1, -1)\n",
    "        # embeddings = self.dropout(embeddings)\n",
    "        lstm_out, (ht, ct) = self.lstm(embeddings)\n",
    "        lstm_out = lstm_out.view(T, -1)\n",
    "        preact_out = self.linear(lstm_out).view(T, -1)\n",
    "        return self.sig(preact_out[-1])\n",
    "    \n",
    "\n",
    "    def pred(self, sentence):\n",
    "        with torch.no_grad():\n",
    "          out = self.forward(sentence)\n",
    "          pred = torch.argmax(out)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de la red neuronal\n",
    "D_in = tam_vocab\n",
    "D_emb = 64\n",
    "D_lstm = 32\n",
    "D_out = num_cat\n",
    "\n",
    "# Épocas de entrenamiento\n",
    "epochs = 200\n",
    "\n",
    "# Learning rate\n",
    "lr =  0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PersuasionLSTM(\n",
       "  (embedding): Embedding(7474, 64)\n",
       "  (lstm): LSTM(64, 32)\n",
       "  (linear): Linear(in_features=32, out_features=6, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasion = PersuasionLSTM(D_in, D_emb, D_lstm, D_out).to(device)\n",
    "persuasion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo los pesos de la capa de embedding del modelo aprendido en [lstm.ipynb](./../Embeddings/lstm.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = './../Embeddings/modelsaves/'\n",
    "filename = 'modelv2-corenlp-emb_64-lstm_32-seed_42069-epochs_299-best-val'\n",
    "state_dict = torch.load(dir_path+filename)\n",
    "\n",
    "persuasion.embedding.load_state_dict(\n",
    "    {\n",
    "      'weight' : state_dict['embedding.weight']   \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congelo la capa de embedding para que no aprenda más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasion.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion.to(device)\n",
    "torch.optim.Adam(\n",
    "    [ \n",
    "        param for param in persuasion.parameters() \n",
    "        if param.requires_grad == True\n",
    "    ], \n",
    "    lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
