{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings con LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import random\n",
    "from itertools import chain\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\n"
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.boletines import get_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\\Embeddings\n"
    }
   ],
   "source": [
    "cd Embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Random Seed:  42069\n"
    }
   ],
   "source": [
    "# Número de GPUs disponibles. Usar 0 para modo CPU.\n",
    "ngpu = 1\n",
    "\n",
    "# Semilla a usar en los generadores de números aleatorios\n",
    "SEED = 42069\n",
    "# SEED = random.randint(1, 10000) # En caso de requerir más resultados\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\"Random Seed: \", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono el tipo de dispositivo a utilizar (gpu o cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Decide si queremos correr en gpu o cpu\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = open('./../mongo_uri.txt', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AMLO\n1. Asegura AMLO que en campaña todo será amor y paz , que los otros candidatos se ahorren sus provocaciones .\n377. “ Y tiene que ver con la alianza de el PRI y de el PAN , no hay que olvidar que los de el PRI , los de el PAN , los de el PRIAN se pusieron de acuerdo para nombrar a los consejeros de el INE , que tampoco son blancas palomas y también se pusieron de acuerdo para nombrar a los magistrados de el Tribunal_Electoral , yo lo denuncié en su momento ” , comentó .\n753. “ Antes en las elecciones pasadas no podíamos defender nos frente_a los ataques a la guerra sucia , a las calumnias , porque nos cercaban , nos daban espacios o actuaban de manera tendenciosa en los medios convencionales , pero en esta elección la diferencia la están marcando las redes sociales , ya no pueden ” , expresó .\n1129. En otro orden de ideas , informó que si hoy fuesen las elecciones ganaría con 25 puntos de ventaja , es bastante el número de mexicanos que lo apoyan , pero hay quienes crearán de manera artificial la polarizar el voto para las elecciones de el 1_de_julio , pero no es lo mismo el 2018 a el 2006 .\n1505. “ Cuánto fue el dinero de el presupuesto que se utilizó para imponer la mal llamada reforma educativa , es una investigación periodística de primer orden , salió hace dos_días en un periódico de que el secretario de Educación ( Aurelio_Nuño ) que se gastó 2_mil_millones_de_pesos , pero eso no es todo , se trata de un año ” , expuso .\n1881. En Autlán_de_Navarro , Jalisco , indicó que se tiene que respetar a los ganadores de la contienda electoral en relación a la Presidencia_de_la_República , pero también a quienes vayan como diputados locales y federales , así_como senadores , presidentes municipales .\n2257. Expresó que se mejorarán los servicios de salud como el ISSSTE y el Seguro , se aumentará a el doble la pensión para adultos mayores será de mil_500_pesos mensuales y para todos , y habrá apoyo para los discapacitados pobres de el país .\n2633. Adelanta AMLO que planteará a Trump un acuerdo de cooperación entre EU , Canadá , México y Centroamérica .\n3009. Indicó que ahora se compra la mitad de la luz que se consume en México a empresas extrajeras que tienen subsidio de 50_mil_millones_de_pesos a el año .\n\nJAMK\n1. José_Antonio_Meade fue recibido en Culiacán por cientos de simpatizantes sinaloenses .\n377. El aspirante presidencial se comprometió a mejorar la infraestructura carretera e hidráulica en la entidad .\n753. “ Si tuviera que resumir en una idea el país por el que apuesto para los próximos seis años , lo resumiría en tres palabras : un México líder ” , indicó .\n1129. De_acuerdo_con diversas estimaciones , las armas en poder de la delincuencia organizada en México podrían alcanzar el número de 1.5 millones de piezas , esto es 3 veces el arsenal con el que cuenta , por_ejemplo , el ejército de Guatemala .\n1505. Expresó que , sin_ninguna_duda y con toda certeza , logrará la victoria el 1_de_julio .\n1881. Dijo que con Mikel_Arriola va por una Ciudad_de_México donde abramos la llave y salga agua , que no sea extorsionada por delegados que condicionan el agua a la militancia política , una ciudad que no tandee el agua , donde el derecho a el agua sea vigente , se eviten las fugas y se evite la corrupción .\n\nRAC\n1. De_la_mano_de jóvenes innovadores , comienza Ricardo_Anaya el camino hacia la Presidencia_de_la_República .\n377. Finalmente , sostuvo que López_Obrador es “ el espanta inversiones ” , porque su actitud provoca que estas se vayan , lo cual es muy delicado , porque cuando no hay inversión no crece la economía y no se generan empleos .\n753. “ Sí , necesitamos cambiar ciertas piezas de el modelo económico , estamos en un momento crítico , donde tenemos que elegir entre volver a el pasado a_través_de un cómic o construir un futuro más incluyente , igualitario , a_partir_de propuestas series , razonadas , en donde los cómo están claros y los para qué , son parte principal de lo que se pretende hacer ” , enfatizó a el contrastar con la propuesta que hace López_Obrador .\n1129. Yo quiero paz para Jalisco , yo quiero paz para México , y esa paz la voy a construir con las mujeres , esa paz la vamos a construir todos juntos ” , enfatizó .\n\n"
    }
   ],
   "source": [
    "sentences = get_sentences(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenvuelvo los grupos de enunciados en un único arreglo con todos los enunciados de todos los candidatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(chain(*sentences.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso los tokens a minúsculas para reducir el tamaño del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "El corpus consta de 6889 enunciados.\n"
    }
   ],
   "source": [
    "corpus = [[w.lower() for w in sent] for sent in corpus]\n",
    "print(f'El corpus consta de {len(corpus)} enunciados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono k oraciones de prueba para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "y se comprometió a regresar como presidente electo para traer el plan de desarrollo para uruapan para decir cuánto se invertirá en la región y regresará cada seis meses para evaluar el plan .\ny es que , dijo , a el debate de el pasado_domingo lópez_obrador se presentó como un hombre profundamente autoritario e incongruente , que desconfía de la sociedad civil y que no tiene un compromiso con el cambio de régimen .\n“ vamos a trabajar junto_a cada uno de los mexicanos hasta asegurar les , a cada uno y a cada una , que sus derechos y las oportunidades que se les deben van a estar ahí ” , prometió en su cierre de campaña en saltillo , coahuila , donde dio por concluidas sus actividades proselitistas por las 32 entidades federativas en_busca_de el voto popular .\nestas adhesiones involucran a mujeres honestas y decididas , que tienen causas en todos los ámbitos de su vida diaria , y que trabajan por el acceso igualitario a la cultura y cuidado de el medio ambiente sostenible , el respeto y rescate de nuestros pueblos originarios , la prevención de adicciones , la lucha por los derechos humanos y , por_supuesto , participación activa en los espacios de decisión y poder .\nandrés_manuel_lópez_obrador encabezó asamblea en comalcalco , donde anunció está de_acuerdo_con la propuesta de la confederación_patronal_de_la_república_mexicana ( coparmex ) para aumentar el salario mínimo de los mexicanos a_partir_de mayo .\ncuento con las mejores propuestas y el mejor perfil : josé_antonio_meade .\ndenuncia_amlo que a los asistentes a sus actos les han robado sus carteras para quitar les las credenciales de elector .\nsu agenda en la materia también plantea una intervención prenatal .\nla mejor política social es la salarial , confirma ricardo_anaya a el presentar el plan que implementará a_partir_de el primer día de su gobierno .\nel candidato presidencial de la coalición todos_por_méxico , josé_antonio_meade , afirmó en san_pedro_mixtepec , oaxaca , que le cambiará el rostro a el estado y trabajará para combatir la pobreza extrema en la primera infancia .\n"
    }
   ],
   "source": [
    "k = 1000\n",
    "sentences = random.sample(corpus, k=k)\n",
    "print('\\n'.join([' '.join(sent) for sent in sentences[::k//10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuento los tokens en todas las oraciones e imprimo los 40 más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(',', 2878), ('pan', 19), ('pobres', 9), ('cuidar', 6), ('centros', 5), ('pusieron', 4), ('ven', 3), ('copia', 2), ('ganaderos', 2), ('exterior', 2), ('dejado', 2), ('consistirá', 2), ('dañino', 1), ('llamando', 1), ('descomponiendo', 1), ('secuestrado', 1), ('la_montaña', 1), ('secretaria', 1), ('proselitismo', 1), ('zavala', 1), ('propuesto', 1), ('intelectual', 1), ('sintetizó', 1), ('elabore', 1), ('hacían', 1)]\n"
    }
   ],
   "source": [
    "freq = sum([Counter(sent) for sent in sentences], Counter())\n",
    "print(freq.most_common()[::209])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Número de tipos: 5202\n"
    }
   ],
   "source": [
    "print(f'Número de tipos: {len(freq.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego un diccionario para pasar de palabra a índice numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_index = {\n",
    "    w : ix\n",
    "    for ix, (w, freq) in enumerate(freq.most_common())\n",
    "    if freq > 1 # No toma en cuenta los hapax\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2314"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "vocab_size = len(w_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "ixBOS = vocab_size\n",
    "ixEOS = vocab_size + 1\n",
    "ixUNK = vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_index[BOS] = ixBOS\n",
    "w_to_index[EOS] = ixEOS\n",
    "w_to_index[UNK] = ixUNK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo el nuevo tamaño del vocabulario después de agregar 3 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2317"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "vocab_size = len(w_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo el diccionario inverso, para convertir de índices a palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_w = [ w for w, ix in w_to_index.items() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexo todo el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_to_index_unk(w):\n",
    "    \"\"\"\n",
    "    Le asigna el token UNK a palabras que no aparezcan en el corpus\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return w_to_index[w] \n",
    "    except KeyError:\n",
    "        return ixUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ejemplos X\n[array([2314,    6,   10,  166,    5,  508,   29,   61,  277,   12,  697,\n          3,  178,    1,   77,   12, 1462,   12,  137, 1053,   10,  579,\n          8,    4,  298,    6,  509,  167,  405,  451,   12, 2316,    3,\n        178,    7]), array([2314, 1054,    2,   27,  840,    4, 1463,    1,    4, 2316,    5,\n          3,  580,    6,    1,    3, 2316,    5,    3,  580,    1, 2316,\n        168,    0,    2,   11,   16,    1, 2316,    0,  210,    1, 2316,\n          7]), array([2314,    8,    3, 2316,    0,    5,  841, 1055, 2316, 2316,    1,\n         49,    0, 1056,    3,  162,    6,  169,    2,    9,  147,    5,\n          9,  698,  842,    1,   99,   85,  843,    0,  159,    3,    1,\n        343,    6,  581,    7])]\nEjemplos Y\n[array([   6,   10,  166,    5,  508,   29,   61,  277,   12,  697,    3,\n        178,    1,   77,   12, 1462,   12,  137, 1053,   10,  579,    8,\n          4,  298,    6,  509,  167,  405,  451,   12, 2316,    3,  178,\n          7, 2315]), array([1054,    2,   27,  840,    4, 1463,    1,    4, 2316,    5,    3,\n        580,    6,    1,    3, 2316,    5,    3,  580,    1, 2316,  168,\n          0,    2,   11,   16,    1, 2316,    0,  210,    1, 2316,    7,\n       2315]), array([   8,    3, 2316,    0,    5,  841, 1055, 2316, 2316,    1,   49,\n          0, 1056,    3,  162,    6,  169,    2,    9,  147,    5,    9,\n        698,  842,    1,   99,   85,  843,    0,  159,    3,    1,  343,\n          6,  581,    7, 2315])]\n"
    }
   ],
   "source": [
    "sentences_ix = [\n",
    "    # Le agrego el inicio y fin de caracter a los enunciados\n",
    "    [ixBOS] + [ w_to_index_unk(w) for w in sent ] + [ixEOS] \n",
    "    for sent in sentences\n",
    "]\n",
    "\n",
    "X = [ np.asarray(sent[:-1]) for sent in sentences_ix ]\n",
    "Y = [ np.asarray(sent[1:]) for sent in sentences_ix ] \n",
    "\n",
    "print('Ejemplos X')\n",
    "print(X[:3])\n",
    "print('Ejemplos Y')\n",
    "print(Y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "700\n300\n"
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mando los vectores de entrada y salida a tensores en gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pytorch_tensor(list_of_lists):\n",
    "    return [\n",
    "        torch.from_numpy(l).long().to(device)\n",
    "        for l in list_of_lists\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = to_pytorch_tensor(X_train)\n",
    "Y_train = to_pytorch_tensor(Y_train)\n",
    "\n",
    "X_test = to_pytorch_tensor(X_test)\n",
    "Y_test = to_pytorch_tensor(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "### 1. Capa de embedding\n",
    "\n",
    "### 2. Capa oculta\n",
    "\n",
    "### 3. Capa de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino las variables para la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión de entrada (one-hot), tamaño del vocabulario\n",
    "D_in = vocab_size\n",
    "\n",
    "# Dimensión de la capa de embedding\n",
    "D_emb = 32 # 32\n",
    "\n",
    "# Dimensión de la capa lstm\n",
    "D_lstm = 16 # 16\n",
    "\n",
    "# Dimensión de la capa de salida\n",
    "D_out = D_in\n",
    "\n",
    "# Épocas de entrenamiento\n",
    "num_epochs = 100\n",
    "\n",
    "# Learning rate\n",
    "lr =  0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ngpu, D_in, D_emb, D_lstm, D_out):\n",
    "        super(Model, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.embedding = nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb)#, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=D_emb, hidden_size=D_lstm, bias=True)#, batch_first=True)\n",
    "        # self.out_layer = nn.Sequential(\n",
    "        #     nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb, padding_idx=0),\n",
    "        #     nn.LSTM(input_size=D_emb, hidden_size=D_lstm, bias=True, batch_first=True),\n",
    "        #     nn.Linear(in_features=D_lstm, out_features=D_out, bias=True),\n",
    "        #     nn.Softmax(dim=D_out)\n",
    "        # )\n",
    "        self.linear = nn.Linear(in_features=D_lstm, out_features=D_out, bias=True)\n",
    "        # self.out_layer = nn.Softmax(dim=1)\n",
    "        # self.out_layer = nn.Sequential(\n",
    "        #     nn.Linear(in_features=D_lstm, out_features=D_out, bias=True),\n",
    "        #     nn.Softmax(dim=1)\n",
    "        # )\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        T = len(sentence)\n",
    "        # print(sentence)\n",
    "        # print(T)\n",
    "\n",
    "        embeddings = self.embedding(sentence).view(T, 1, -1)\n",
    "        # print('Embeddings')\n",
    "        # print(embeddings)\n",
    "\n",
    "        lstm_out, (ht, ct) = self.lstm(embeddings)\n",
    "        lstm_out = lstm_out.view(T, -1)\n",
    "        # print('LSTM_out')\n",
    "        # print(lstm_out)\n",
    "\n",
    "        preact_out = self.linear(lstm_out).view(T, -1)\n",
    "        # print('Preact out')\n",
    "        # print(preact_out)\n",
    "\n",
    "        return F.log_softmax(preact_out, dim=1)\n",
    "        # return self.out_layer(preact_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Model(\n  (embedding): Embedding(2317, 32)\n  (lstm): LSTM(32, 16)\n  (linear): Linear(in_features=16, out_features=2317, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "model = Model(ngpu, D_in, D_emb, D_lstm, D_out).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de pesos\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Embedding') != -1:\n",
    "#         # Regularizo los pesos\n",
    "#         n = m.num_embeddings\n",
    "#         y = 1.0/np.sqrt(n)\n",
    "#         m.weight.data.uniform_(-y, y)\n",
    "#     elif classname.find('Linear') != -1:\n",
    "#         n = m.in_features\n",
    "#         y = 1.0/np.sqrt(n)\n",
    "#         m.weight.data.uniform_(-y, y)\n",
    "#         m.bias.data.fill_(0)\n",
    "#     elif classname.find('LSTM') != -1:\n",
    "#         n = m.input_size\n",
    "#         y = 1.0/np.sqrt(n)\n",
    "#         m.weight_ih_l0.data.uniform_(-y, y)\n",
    "#         m.weight_hh_l0.data.uniform_(-y, y)\n",
    "#         m.bias_ih_l0.data.fill_(0)\n",
    "#         m.bias_hh_l0.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropía cruzada como optmizador y SGD como optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Coste después de 1 épocas: 7.746129035949707\nCoste después de 2 épocas: 7.71807861328125\nCoste después de 3 épocas: 7.68988037109375\nCoste después de 4 épocas: 7.66145133972168\nCoste después de 5 épocas: 7.632718086242676\nCoste después de 6 épocas: 7.603597640991211\nCoste después de 7 épocas: 7.574005603790283\nCoste después de 8 épocas: 7.543843746185303\nCoste después de 9 épocas: 7.513016223907471\nCoste después de 10 épocas: 7.481410503387451\nCoste después de 11 épocas: 7.448909282684326\nCoste después de 12 épocas: 7.415383338928223\nCoste después de 13 épocas: 7.380686283111572\nCoste después de 14 épocas: 7.344662666320801\nCoste después de 15 épocas: 7.307144641876221\nCoste después de 16 épocas: 7.26794958114624\nCoste después de 17 épocas: 7.226873874664307\nCoste después de 18 épocas: 7.183696269989014\nCoste después de 19 épocas: 7.138185977935791\nCoste después de 20 épocas: 7.090075492858887\nCoste después de 21 épocas: 7.039078235626221\nCoste después de 22 épocas: 6.984867572784424\nCoste después de 23 épocas: 6.927060127258301\nCoste después de 24 épocas: 6.86521577835083\nCoste después de 25 épocas: 6.798820972442627\nCoste después de 26 épocas: 6.727283954620361\nCoste después de 27 épocas: 6.649954319000244\nCoste después de 28 épocas: 6.566141128540039\nCoste después de 29 épocas: 6.475189685821533\nCoste después de 30 épocas: 6.376601696014404\nCoste después de 31 épocas: 6.270259380340576\nCoste después de 32 épocas: 6.156766414642334\nCoste después de 33 épocas: 6.037907123565674\nCoste después de 34 épocas: 5.916982650756836\nCoste después de 35 épocas: 5.798680782318115\nCoste después de 36 épocas: 5.688089847564697\nCoste después de 37 épocas: 5.589166164398193\nCoste después de 38 épocas: 5.503712177276611\nCoste después de 39 épocas: 5.431556701660156\nCoste después de 40 épocas: 5.371396541595459\nCoste después de 41 épocas: 5.321507453918457\nCoste después de 42 épocas: 5.280135631561279\nCoste después de 43 épocas: 5.245705604553223\nCoste después de 44 épocas: 5.216890335083008\nCoste después de 45 épocas: 5.192593574523926\nCoste después de 46 épocas: 5.171900749206543\nCoste después de 47 épocas: 5.154046535491943\nCoste después de 48 épocas: 5.138397693634033\nCoste después de 49 épocas: 5.124447822570801\nCoste después de 50 épocas: 5.111804008483887\nCoste después de 51 épocas: 5.100179195404053\nCoste después de 52 épocas: 5.089366912841797\nCoste después de 53 épocas: 5.079228401184082\nCoste después de 54 épocas: 5.069666862487793\nCoste después de 55 épocas: 5.060625076293945\nCoste después de 56 épocas: 5.052058696746826\nCoste después de 57 épocas: 5.043942451477051\nCoste después de 58 épocas: 5.036254405975342\nCoste después de 59 épocas: 5.028976917266846\nCoste después de 60 épocas: 5.022089958190918\nCoste después de 61 épocas: 5.015578746795654\nCoste después de 62 épocas: 5.009423732757568\nCoste después de 63 épocas: 5.003604888916016\nCoste después de 64 épocas: 4.998103141784668\nCoste después de 65 épocas: 4.992895126342773\nCoste después de 66 épocas: 4.987962245941162\nCoste después de 67 épocas: 4.983283042907715\nCoste después de 68 épocas: 4.978837966918945\nCoste después de 69 épocas: 4.974606513977051\nCoste después de 70 épocas: 4.970571994781494\nCoste después de 71 épocas: 4.966716766357422\nCoste después de 72 épocas: 4.963024139404297\nCoste después de 73 épocas: 4.959479808807373\nCoste después de 74 épocas: 4.956070423126221\nCoste después de 75 épocas: 4.952783107757568\nCoste después de 76 épocas: 4.949609279632568\nCoste después de 77 épocas: 4.946535110473633\nCoste después de 78 épocas: 4.943554878234863\nCoste después de 79 épocas: 4.940659523010254\nCoste después de 80 épocas: 4.937841415405273\nCoste después de 81 épocas: 4.935096263885498\nCoste después de 82 épocas: 4.932415008544922\nCoste después de 83 épocas: 4.929795742034912\nCoste después de 84 épocas: 4.927230358123779\nCoste después de 85 épocas: 4.924717903137207\nCoste después de 86 épocas: 4.922252178192139\nCoste después de 87 épocas: 4.9198317527771\nCoste después de 88 épocas: 4.917450904846191\nCoste después de 89 épocas: 4.915109157562256\nCoste después de 90 épocas: 4.912802219390869\nCoste después de 91 épocas: 4.91052770614624\nCoste después de 92 épocas: 4.908284664154053\nCoste después de 93 épocas: 4.906069755554199\nCoste después de 94 épocas: 4.903879642486572\nCoste después de 95 épocas: 4.901717662811279\nCoste después de 96 épocas: 4.899577617645264\nCoste después de 97 épocas: 4.897458553314209\nCoste después de 98 épocas: 4.895362377166748\nCoste después de 99 épocas: 4.893284320831299\nCoste después de 100 épocas: 4.891226291656494\n"
    }
   ],
   "source": [
    "# for epoch in tqdm(range(num_epochs)):\n",
    "for epoch in range(num_epochs):\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "    # for x, y in tqdm(zip(X_train, Y_train)):\n",
    "        if len(x) == 0:\n",
    "            tqdm.write('Sentencia vacía')\n",
    "            continue\n",
    "        # Limpiamos gradientes acumulados\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        # print(x)\n",
    "        pred = model(x)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # break\n",
    "    # tqdm.write(f'Epoch: {epoch:>12} Loss: {loss}')\n",
    "    # break\n",
    "    print(f'Coste después de {epoch+1} épocas: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ix_sentence(sentence):\n",
    "    print(' '.join(index_to_w[ix] for ix in sentence.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===================================================\n- Probando enunciado:\n<BOS> añadió que <UNK> <UNK> de los funcionarios en diferentes niveles de gobierno , <UNK> y federal , para <UNK> <UNK> la ley , por lo que hizo un llamado a las autoridades para investigar a todos los <UNK> en el <UNK> .\n\n- Predicción:\n<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> , <UNK> <UNK> <UNK> <UNK> , , <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> , <EOS>\n===================================================\n- Probando enunciado:\n<BOS> anuncia que mañana dará_a_conocer el programa de gira de la fase que será presidente electo .\n\n- Predicción:\n<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <EOS>\n===================================================\n- Probando enunciado:\n<BOS> lópez_obrador comenta : “ como no voy a desear el apoyo de el ingeniero cárdenas por todo lo que significa , lo respeto mucho ” .\n\n- Predicción:\n<UNK> <UNK> <UNK> <UNK> , <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <EOS>\n===================================================\n- Probando enunciado:\n<BOS> dio_a_conocer que los paisanos migrantes <UNK> a sus familiares <UNK> a el año , eso demuestra que el pueblo sea bueno y trabajador , la entidad tiene todo , pero lo que falta y es lo que ya se va a conseguir : un buen gobierno , con eso veracruz y méxico saldrán adelante .\n\n- Predicción:\n<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <EOS> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <EOS>\n===================================================\n- Probando enunciado:\n<BOS> para mañana visitará <UNK> , comitán_de_domínguez , chiapas .\n\n- Predicción:\n<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <EOS>\n"
    }
   ],
   "source": [
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    for sentence in X_test[:5]:\n",
    "        print('===================================================')\n",
    "        print('- Probando enunciado:')\n",
    "        print_ix_sentence(sentence)\n",
    "        print()\n",
    "\n",
    "        out = model(sentence)\n",
    "        prediccion = torch.argmax(out, dim=1)\n",
    "        print('- Predicción:')\n",
    "        print_ix_sentence(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitaypit20202conda2eb9642ad5e346f38de29b14c14576bc",
   "display_name": "Python 3.7.7 64-bit ('aypit-2020-2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}