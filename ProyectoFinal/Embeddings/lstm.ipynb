{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings con LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import random\n",
    "from itertools import chain\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\n"
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.boletines import get_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\\Embeddings\n"
    }
   ],
   "source": [
    "cd Embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Random Seed:  42069\n"
    }
   ],
   "source": [
    "# Número de GPUs disponibles. Usar 0 para modo CPU.\n",
    "ngpu = 1\n",
    "\n",
    "# Semilla a usar en los generadores de números aleatorios\n",
    "SEED = 42069\n",
    "# SEED = random.randint(1, 10000) # En caso de requerir más resultados\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\"Random Seed: \", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono el tipo de dispositivo a utilizar (gpu o cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Decide si queremos correr en gpu o cpu\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = open('./../mongo_uri.txt', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AMLO\n1. Asegura AMLO que en campaña todo será amor y paz , que los otros candidatos se ahorren sus provocaciones .\n377. “ Y tiene que ver con la alianza de el PRI y de el PAN , no hay que olvidar que los de el PRI , los de el PAN , los de el PRIAN se pusieron de acuerdo para nombrar a los consejeros de el INE , que tampoco son blancas palomas y también se pusieron de acuerdo para nombrar a los magistrados de el Tribunal_Electoral , yo lo denuncié en su momento ” , comentó .\n753. “ Antes en las elecciones pasadas no podíamos defender nos frente_a los ataques a la guerra sucia , a las calumnias , porque nos cercaban , nos daban espacios o actuaban de manera tendenciosa en los medios convencionales , pero en esta elección la diferencia la están marcando las redes sociales , ya no pueden ” , expresó .\n1129. En otro orden de ideas , informó que si hoy fuesen las elecciones ganaría con 25 puntos de ventaja , es bastante el número de mexicanos que lo apoyan , pero hay quienes crearán de manera artificial la polarizar el voto para las elecciones de el 1_de_julio , pero no es lo mismo el 2018 a el 2006 .\n1505. “ Cuánto fue el dinero de el presupuesto que se utilizó para imponer la mal llamada reforma educativa , es una investigación periodística de primer orden , salió hace dos_días en un periódico de que el secretario de Educación ( Aurelio_Nuño ) que se gastó 2_mil_millones_de_pesos , pero eso no es todo , se trata de un año ” , expuso .\n1881. En Autlán_de_Navarro , Jalisco , indicó que se tiene que respetar a los ganadores de la contienda electoral en relación a la Presidencia_de_la_República , pero también a quienes vayan como diputados locales y federales , así_como senadores , presidentes municipales .\n2257. Expresó que se mejorarán los servicios de salud como el ISSSTE y el Seguro , se aumentará a el doble la pensión para adultos mayores será de mil_500_pesos mensuales y para todos , y habrá apoyo para los discapacitados pobres de el país .\n2633. Adelanta AMLO que planteará a Trump un acuerdo de cooperación entre EU , Canadá , México y Centroamérica .\n3009. Indicó que ahora se compra la mitad de la luz que se consume en México a empresas extrajeras que tienen subsidio de 50_mil_millones_de_pesos a el año .\n\nRAC\n1. De_la_mano_de jóvenes innovadores , comienza Ricardo_Anaya el camino hacia la Presidencia_de_la_República .\n377. Finalmente , sostuvo que López_Obrador es “ el espanta inversiones ” , porque su actitud provoca que estas se vayan , lo cual es muy delicado , porque cuando no hay inversión no crece la economía y no se generan empleos .\n753. “ Sí , necesitamos cambiar ciertas piezas de el modelo económico , estamos en un momento crítico , donde tenemos que elegir entre volver a el pasado a_través_de un cómic o construir un futuro más incluyente , igualitario , a_partir_de propuestas series , razonadas , en donde los cómo están claros y los para qué , son parte principal de lo que se pretende hacer ” , enfatizó a el contrastar con la propuesta que hace López_Obrador .\n1129. Yo quiero paz para Jalisco , yo quiero paz para México , y esa paz la voy a construir con las mujeres , esa paz la vamos a construir todos juntos ” , enfatizó .\n\nJAMK\n1. José_Antonio_Meade fue recibido en Culiacán por cientos de simpatizantes sinaloenses .\n377. El aspirante presidencial se comprometió a mejorar la infraestructura carretera e hidráulica en la entidad .\n753. “ Si tuviera que resumir en una idea el país por el que apuesto para los próximos seis años , lo resumiría en tres palabras : un México líder ” , indicó .\n1129. De_acuerdo_con diversas estimaciones , las armas en poder de la delincuencia organizada en México podrían alcanzar el número de 1.5 millones de piezas , esto es 3 veces el arsenal con el que cuenta , por_ejemplo , el ejército de Guatemala .\n1505. Expresó que , sin_ninguna_duda y con toda certeza , logrará la victoria el 1_de_julio .\n1881. Dijo que con Mikel_Arriola va por una Ciudad_de_México donde abramos la llave y salga agua , que no sea extorsionada por delegados que condicionan el agua a la militancia política , una ciudad que no tandee el agua , donde el derecho a el agua sea vigente , se eviten las fugas y se evite la corrupción .\n\n"
    }
   ],
   "source": [
    "sentences = get_sentences(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenvuelvo los grupos de enunciados en un único arreglo con todos los enunciados de todos los candidatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(chain(*sentences.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso los tokens a minúsculas para reducir el tamaño del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "El corpus consta de 6889 enunciados.\n"
    }
   ],
   "source": [
    "corpus = [[w.lower() for w in sent] for sent in corpus]\n",
    "print(f'El corpus consta de {len(corpus)} enunciados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono k oraciones de prueba para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "y se comprometió a regresar como presidente electo para traer el plan de desarrollo para uruapan para decir cuánto se invertirá en la región y regresará cada seis meses para evaluar el plan .\npreviamente , lópez_obrador denunció que están haciendo llamadas telefónicas a_el_por_mayor a ciudadanos para difamar lo y describió que las llamadas provienen de número telefónicos de el país y de el extranjero , es un bombardeo de llamadas .\nindicó que la zona franca se mantuvo en toda la línea fronteriza en la época de porfirio_díaz , después en la revolución_mexicana , hasta que llegó carlos_salinas_de_gortari que acabó con el apoyo en la frontera .\nlamentó la violencia que vive el país y confió en que a_pesar_de la situación , la gente saldrá a votar , porque tiene mucho interés en participar el 1_de_julio .\na su salida , entrevistado por los medios de comunicación , reiteró su llamado a el voto útil , invitando a las y los ciudadanos a participar libremente en el proyecto de coalición , y cerrando la puerta a los pactos cupulares .\nmeade asumió siete compromisos puntuales para combatir la inseguridad y ofreció una nación libre de violencia , corrupción y marginación .\nadelantó que regresará como presidente electo para traer el plan de desarrollo e informará cuánto invertirá en actividades productivas , infraestructura y desarrollo social por pueblo , localidad , municipios y la región , se le dará seguimiento , se evaluará entre todos .\nhay gente buena , militante o no militante de partidos políticos .\nlópez_obrador respondió que el caso de mireles ya se ve en el tribunal_electoral , mientras tanto el doctor es “ nuestro candidato ” .\nandrés_manuel_lópez_obrador pidió el voto parejo por los candidatos de la coalición “ juntos haremos historia ” .\n“ estamos viviendo un momento estelar en la historia de méxico y ustedes son protagonistas fundamentales , yo confío mucho en ustedes , porque son gente consciente , mujeres y hombres con convicción , les mando un abrazo fuerte ” , finalizó .\n"
    }
   ],
   "source": [
    "k = 6889\n",
    "sentences = random.sample(corpus, k=k)\n",
    "print('\\n'.join([' '.join(sent) for sent in sentences[::k//10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['El', 'gato', 'come', 'croquetas', '.'],\n ['El', 'perro', 'come', 'croquetas', '.'],\n ['El', 'gato', 'come', 'atún', '.'],\n ['El', 'perro', 'come', 'pollo', '.'],\n ['El', 'pollo', 'juega', '.'],\n ['El', 'perro', 'juega', '.'],\n ['El', 'gato', 'juega', '.'],\n ['El', 'pollo', 'juega', '.'],\n ['El', 'atún', 'come', '.'],\n ['El', 'pollo', 'come', '.'],\n ['El', 'gato', 'juega', 'con', 'el', 'perro', '.'],\n ['El', 'gato', 'juega', 'con', 'el', 'pollo', '.'],\n ['El', 'perro', 'juega', 'con', 'el', 'gato', '.'],\n ['El', 'perro', 'juega', 'con', 'el', 'pollo', '.'],\n ['El', 'pollo', 'juega', 'con', 'el', 'perro', '.'],\n ['El', 'pollo', 'juega', 'con', 'el', 'gato', '.']]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# corpus juguete\n",
    "sentences = open('corpus_juguete.txt', 'r', encoding='utf-8').readlines()\n",
    "sentences = [s.strip().split(' ') for s in sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuento los tokens en todas las oraciones e imprimo los 40 más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = sum([Counter(sent) for sent in sentences], Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Número de tipos: 11\n[('El', 16), ('.', 16), ('juega', 10), ('pollo', 8), ('gato', 7), ('perro', 7), ('come', 6), ('con', 6), ('el', 6), ('croquetas', 2), ('atún', 2)]\n"
    }
   ],
   "source": [
    "n_tipos = len(freq.keys())\n",
    "print(f'Número de tipos: {n_tipos}')\n",
    "print(freq.most_common()[::max(n_tipos//25, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego un diccionario para pasar de palabra a índice numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_index = {\n",
    "    w : ix\n",
    "    for ix, (w, freq) in enumerate(freq.most_common())\n",
    "    if freq > 1 # No toma en cuenta los hapax\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "11"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "vocab_size = len(w_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "ixBOS = vocab_size\n",
    "ixEOS = vocab_size + 1\n",
    "ixUNK = vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_index[BOS] = ixBOS\n",
    "w_to_index[EOS] = ixEOS\n",
    "w_to_index[UNK] = ixUNK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo el nuevo tamaño del vocabulario después de agregar 3 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "14"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "vocab_size = len(w_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo el diccionario inverso, para convertir de índices a palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_w = [ w for w, ix in w_to_index.items() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexo todo el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_to_index_unk(w):\n",
    "    \"\"\"\n",
    "    Le asigna el token UNK a palabras que no aparezcan en el corpus\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return w_to_index[w] \n",
    "    except KeyError:\n",
    "        return ixUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ejemplos X\n[array([11,  0,  4,  6,  9,  1]), array([11,  0,  5,  6,  9,  1]), array([11,  0,  4,  6, 10,  1])]\nEjemplos Y\n[array([ 0,  4,  6,  9,  1, 12]), array([ 0,  5,  6,  9,  1, 12]), array([ 0,  4,  6, 10,  1, 12])]\n"
    }
   ],
   "source": [
    "sentences_ix = [\n",
    "    # Le agrego el inicio y fin de caracter a los enunciados\n",
    "    [ixBOS] + [ w_to_index_unk(w) for w in sent ] + [ixEOS] \n",
    "    for sent in sentences\n",
    "]\n",
    "\n",
    "X = [ np.asarray(sent[:-1]) for sent in sentences_ix ]\n",
    "Y = [ np.asarray(sent[1:]) for sent in sentences_ix ] \n",
    "\n",
    "print('Ejemplos X')\n",
    "print(X[:3])\n",
    "print('Ejemplos Y')\n",
    "print(Y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12\n4\n"
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mando los vectores de entrada y salida a tensores en gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pytorch_tensor(list_of_lists):\n",
    "    return [\n",
    "        torch.from_numpy(l).long().to(device)\n",
    "        for l in list_of_lists\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = to_pytorch_tensor(X_train)\n",
    "Y_train = to_pytorch_tensor(Y_train)\n",
    "\n",
    "X_test = to_pytorch_tensor(X_test)\n",
    "Y_test = to_pytorch_tensor(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "### 1. Capa de embedding\n",
    "\n",
    "### 2. Capa oculta\n",
    "\n",
    "### 3. Capa de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino las variables para la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión de entrada (one-hot), tamaño del vocabulario\n",
    "D_in = vocab_size\n",
    "\n",
    "# Dimensión de la capa de embedding\n",
    "D_emb = 2 # 32\n",
    "\n",
    "# Dimensión de la capa lstm\n",
    "D_lstm = 4 # 16\n",
    "\n",
    "# Dimensión de la capa de salida\n",
    "D_out = D_in\n",
    "\n",
    "# Épocas de entrenamiento\n",
    "num_epochs = 300\n",
    "\n",
    "# Betas para Adam\n",
    "beta1 = 0.0001\n",
    "beta2 = 0.99\n",
    "\n",
    "# Learning rate\n",
    "lr =  0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ngpu, D_in, D_emb, D_lstm, D_out):\n",
    "        super(Model, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.embedding = nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb)#, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=D_emb, hidden_size=D_lstm) #, bias=True)#, batch_first=True)\n",
    "        # self.out_layer = nn.Sequential(\n",
    "        #     nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb, padding_idx=0),\n",
    "        #     nn.LSTM(input_size=D_emb, hidden_size=D_lstm, bias=True, batch_first=True),\n",
    "        #     nn.Linear(in_features=D_lstm, out_features=D_out, bias=True),\n",
    "        #     nn.Softmax(dim=D_out)\n",
    "        # )\n",
    "        self.linear = nn.Linear(in_features=D_lstm, out_features=D_out) #, bias=True)\n",
    "        # self.out_layer = nn.Softmax(dim=1)\n",
    "        # self.out_layer = nn.Sequential(\n",
    "        #     nn.Linear(in_features=D_lstm, out_features=D_out, bias=True),\n",
    "        #     nn.Softmax(dim=1)\n",
    "        # )\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        T = len(sentence)\n",
    "        # print(sentence)\n",
    "        # print(T)\n",
    "\n",
    "        embeddings = self.embedding(sentence).view(T, 1, -1)\n",
    "        # print('Embeddings')\n",
    "        # print(embeddings)\n",
    "\n",
    "        lstm_out, (ht, ct) = self.lstm(embeddings)\n",
    "        lstm_out = lstm_out.view(T, -1)\n",
    "        # print('LSTM_out')\n",
    "        # print(lstm_out)\n",
    "\n",
    "        preact_out = self.linear(lstm_out).view(T, -1)\n",
    "        # print('Preact out')\n",
    "        # print(preact_out)\n",
    "\n",
    "        return F.log_softmax(preact_out, dim=1)\n",
    "        # return self.out_layer(preact_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Model(\n  (embedding): Embedding(14, 2)\n  (lstm): LSTM(2, 4)\n  (linear): Linear(in_features=4, out_features=14, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "model = Model(ngpu, D_in, D_emb, D_lstm, D_out).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de pesos\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Embedding') != -1:\n",
    "#         # Regularizo los pesos\n",
    "#         n = m.num_embeddings\n",
    "#         y = 1.0/np.sqrt(n)\n",
    "#         m.weight.data.uniform_(-y, y)\n",
    "#     elif classname.find('Linear') != -1:\n",
    "#         n = m.in_features\n",
    "#         y = 1.0/np.sqrt(n)\n",
    "#         m.weight.data.uniform_(-y, y)\n",
    "#         m.bias.data.fill_(0)\n",
    "#     elif classname.find('LSTM') != -1:\n",
    "#         n = m.input_size\n",
    "#         y = 1.0/np.sqrt(n)\n",
    "#         m.weight_ih_l0.data.uniform_(-y, y)\n",
    "#         m.weight_hh_l0.data.uniform_(-y, y)\n",
    "#         m.bias_ih_l0.data.fill_(0)\n",
    "#         m.bias_hh_l0.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropía cruzada como optmizador y SGD como optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "criterion.to(device)\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Coste después de 1 épocas: 32.912123680114746\nCoste después de 21 épocas: 26.16660439968109\nCoste después de 41 épocas: 21.43843638896942\nCoste después de 61 épocas: 17.623829245567322\nCoste después de 81 épocas: 14.907564878463745\nCoste después de 101 épocas: 13.018669664859772\nCoste después de 121 épocas: 11.261499226093292\nCoste después de 141 épocas: 10.043642461299896\nCoste después de 161 épocas: 9.256027340888977\nCoste después de 181 épocas: 8.716104090213776\nCoste después de 201 épocas: 8.32496953010559\nCoste después de 221 épocas: 8.0212881565094\nCoste después de 241 épocas: 7.772305369377136\nCoste después de 261 épocas: 7.565344154834747\nCoste después de 281 épocas: 7.389778196811676\nWall time: 16.8 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "# for epoch in range(10):\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "    # for x, y in tqdm(zip(X_train, Y_train)):\n",
    "        if len(x) == 0:\n",
    "            tqdm.write('Sentencia vacía')\n",
    "            continue\n",
    "        # Limpiamos gradientes acumulados\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        # print(x)\n",
    "        out = model(x)\n",
    "        # with torch.no_grad():\n",
    "        #     pred = torch.argmax(out, dim=1)\n",
    "        #     print('Pred:')\n",
    "        #     print(pred)\n",
    "        #     print('y:')\n",
    "        #     print(y)\n",
    "        #     print('\\n')\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        # optimizer.zero_grad()\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        # break\n",
    "    # tqdm.write(f'Epoch: {epoch:>12} Loss: {loss}')\n",
    "    # break\n",
    "    if epoch%20 == 0:\n",
    "        print(f'Coste después de {epoch+1} épocas: {epoch_loss}')\n",
    "    # if epoch%10 == 0:\n",
    "    #     print(list(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ix_sentence(sentence):\n",
    "    print(' '.join(index_to_w[ix] for ix in sentence.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===================================================\n- Probando enunciado:\n<BOS> El pollo juega .\n\n- Predicción:\nEl pollo come . <EOS>\n- Real:\nEl pollo juega . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> El gato juega .\n\n- Predicción:\nEl pollo come . <EOS>\n- Real:\nEl gato juega . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> El perro juega con el pollo .\n\n- Predicción:\nEl pollo come . el perro . <EOS>\n- Real:\nEl perro juega con el pollo . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> El perro juega con el gato .\n\n- Predicción:\nEl pollo come . el perro . <EOS>\n- Real:\nEl perro juega con el gato . <EOS>\n\n\n"
    }
   ],
   "source": [
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    for sentence, y in zip(X_test[:10], Y_test[:10]):\n",
    "        print('===================================================')\n",
    "        print('- Probando enunciado:')\n",
    "        print_ix_sentence(sentence)\n",
    "        print()\n",
    "\n",
    "        out = model(sentence)\n",
    "        prediccion = torch.argmax(out, dim=1)\n",
    "        print('- Predicción:')\n",
    "        print_ix_sentence(prediccion)\n",
    "        print\n",
    "        print('- Real:')\n",
    "        print_ix_sentence(y)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('embedding.weight',\n  Parameter containing:\n  tensor([[ 1.5763e+00,  1.8883e+00],\n          [-3.1118e-01,  2.9560e+00],\n          [ 8.2579e-01,  6.5034e-01],\n          [ 9.8333e-01,  2.0115e-03],\n          [ 3.1403e+00,  1.0659e+00],\n          [ 1.4121e+00, -1.2882e+00],\n          [-8.7647e-01, -2.7509e+00],\n          [ 1.1388e+00, -1.8062e+00],\n          [-1.6106e+00, -1.9376e-01],\n          [-9.6354e-02,  1.5616e-01],\n          [ 7.8684e-01,  8.0852e-01],\n          [-2.4859e+00,  1.8976e+00],\n          [ 1.5199e+00, -5.5874e-02],\n          [ 7.6869e-01,  9.7801e-01]], device='cuda:0', requires_grad=True)),\n ('lstm.weight_ih_l0',\n  Parameter containing:\n  tensor([[-0.4469,  0.2968],\n          [-0.1957,  0.0548],\n          [ 0.9771,  0.0629],\n          [-0.0707,  0.2599],\n          [-0.0821, -0.0852],\n          [ 1.9162, -0.0691],\n          [ 0.4111, -0.7245],\n          [ 1.2450, -1.0642],\n          [-1.5671,  0.3374],\n          [ 1.9145,  0.9841],\n          [-0.4381,  0.4918],\n          [ 0.8720, -1.7369],\n          [ 0.3080,  2.0343],\n          [ 0.3152,  0.2100],\n          [ 0.7408, -0.1459],\n          [ 0.1050,  0.3341]], device='cuda:0', requires_grad=True)),\n ('lstm.weight_hh_l0',\n  Parameter containing:\n  tensor([[-0.2272,  0.2024, -0.0716, -0.2750],\n          [-1.8742,  0.8473, -1.0356,  0.1624],\n          [-0.4106, -0.0076, -0.6271,  0.1379],\n          [-0.8371, -0.0347, -0.6288,  0.1732],\n          [-0.7672,  0.3944,  0.0844,  0.5689],\n          [-0.0691, -0.6538, -0.0478, -0.4176],\n          [ 0.2692, -0.1341,  0.3344, -0.9170],\n          [ 0.6533, -0.4154, -0.2756,  0.2333],\n          [ 0.7142,  0.4085, -0.1034,  0.0276],\n          [-0.2812,  0.0181, -0.1746, -0.2977],\n          [-1.3932,  1.2640,  0.2707,  1.2092],\n          [-1.0160, -0.2342, -0.9455,  0.1853],\n          [-0.1975, -1.0726,  0.5072, -0.5799],\n          [-0.1879,  0.3174, -0.4913,  0.3248],\n          [-0.4946,  0.2609, -0.5601, -0.4032],\n          [-1.0462,  0.3237, -0.1565,  0.0695]], device='cuda:0',\n         requires_grad=True)),\n ('lstm.bias_ih_l0',\n  Parameter containing:\n  tensor([ 1.5091,  1.2384,  0.9394,  1.4613,  0.5225, -0.3692,  0.3824,  0.1322,\n          -0.8773, -0.3994, -0.2408,  0.2543,  1.2313,  2.2396,  1.2717,  1.8858],\n         device='cuda:0', requires_grad=True)),\n ('lstm.bias_hh_l0',\n  Parameter containing:\n  tensor([ 1.2282,  1.1405,  0.9540,  1.7812,  0.7898,  0.0269, -0.0221, -0.0583,\n          -0.9998,  0.5359,  0.5804,  0.7966,  1.1956,  1.7266,  1.2702,  1.9246],\n         device='cuda:0', requires_grad=True)),\n ('linear.weight',\n  Parameter containing:\n  tensor([[ 6.0419e+00, -1.8990e+00,  1.5289e+00, -2.2839e+00],\n          [-3.0533e+00, -9.9533e-01, -4.6664e-04,  4.6298e+00],\n          [-1.0376e+00,  2.2471e+00, -2.8217e+00, -3.1631e-01],\n          [ 2.5823e-01, -2.6202e+00, -7.6315e-01, -1.2902e+00],\n          [ 7.7939e-02, -1.5977e+00,  3.7294e-01, -2.4415e+00],\n          [-5.0398e-01, -2.1142e+00,  7.9234e-01, -2.2962e+00],\n          [-8.7162e-01,  2.4654e+00, -2.6839e+00, -2.8342e-01],\n          [-1.5199e+00,  2.9930e+00,  6.6851e-01,  2.0717e+00],\n          [ 1.9669e-01,  2.1806e+00,  3.2091e+00,  3.0524e+00],\n          [ 5.1995e-01, -2.4344e+00, -1.3609e+00,  2.0917e+00],\n          [ 7.1102e-01, -1.8995e+00, -9.3295e-01, -3.1450e-01],\n          [ 5.8549e-01,  2.6640e-01,  5.6592e-01,  7.4256e-02],\n          [-1.8677e+00,  3.0424e+00,  2.9060e+00, -3.8959e+00],\n          [ 6.7156e-01, -1.2559e-01,  5.0601e-01,  5.6181e-02]], device='cuda:0',\n         requires_grad=True)),\n ('linear.bias',\n  Parameter containing:\n  tensor([ 1.2276,  0.2040, -0.1794,  1.2606,  1.0835,  0.9444,  0.1762, -0.3637,\n          -0.5542, -0.3094,  1.1018, -1.8817, -1.0839, -1.9074], device='cuda:0',\n         requires_grad=True))]"
     },
     "metadata": {},
     "execution_count": 254
    }
   ],
   "source": [
    "# params = list(model.named_parameters())\n",
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(params[0][1].unfold(0, 14, 1)[0], params[0][1].unfold(0, 14, 1)[1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params[0][1].unfold(0, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitaypit20202conda2eb9642ad5e346f38de29b14c14576bc",
   "display_name": "Python 3.7.7 64-bit ('aypit-2020-2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}