{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings con LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "import random\n",
    "from itertools import chain\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\n"
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.boletines import get_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\\Embeddings\n"
    }
   ],
   "source": [
    "cd Embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Random Seed:  42069\n"
    }
   ],
   "source": [
    "# Número de GPUs disponibles. Usar 0 para modo CPU.\n",
    "ngpu = 1\n",
    "\n",
    "# Semilla a usar en los generadores de números aleatorios\n",
    "SEED = 42069\n",
    "# SEED = random.randint(1, 10000) # En caso de requerir más resultados\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\"Random Seed: \", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono el tipo de dispositivo a utilizar (gpu o cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Decide si queremos correr en gpu o cpu\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = open('./../mongo_uri.txt', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RAC\n1. De_la_mano_de jóvenes innovadores , comienza Ricardo_Anaya el camino hacia la Presidencia_de_la_República .\n377. Finalmente , sostuvo que López_Obrador es “ el espanta inversiones ” , porque su actitud provoca que estas se vayan , lo cual es muy delicado , porque cuando no hay inversión no crece la economía y no se generan empleos .\n753. “ Sí , necesitamos cambiar ciertas piezas de el modelo económico , estamos en un momento crítico , donde tenemos que elegir entre volver a el pasado a_través_de un cómic o construir un futuro más incluyente , igualitario , a_partir_de propuestas series , razonadas , en donde los cómo están claros y los para qué , son parte principal de lo que se pretende hacer ” , enfatizó a el contrastar con la propuesta que hace López_Obrador .\n1129. Yo quiero paz para Jalisco , yo quiero paz para México , y esa paz la voy a construir con las mujeres , esa paz la vamos a construir todos juntos ” , enfatizó .\n\nJAMK\n1. José_Antonio_Meade fue recibido en Culiacán por cientos de simpatizantes sinaloenses .\n377. El aspirante presidencial se comprometió a mejorar la infraestructura carretera e hidráulica en la entidad .\n753. “ Si tuviera que resumir en una idea el país por el que apuesto para los próximos seis años , lo resumiría en tres palabras : un México líder ” , indicó .\n1129. De_acuerdo_con diversas estimaciones , las armas en poder de la delincuencia organizada en México podrían alcanzar el número de 1.5 millones de piezas , esto es 3 veces el arsenal con el que cuenta , por_ejemplo , el ejército de Guatemala .\n1505. Expresó que , sin_ninguna_duda y con toda certeza , logrará la victoria el 1_de_julio .\n1881. Dijo que con Mikel_Arriola va por una Ciudad_de_México donde abramos la llave y salga agua , que no sea extorsionada por delegados que condicionan el agua a la militancia política , una ciudad que no tandee el agua , donde el derecho a el agua sea vigente , se eviten las fugas y se evite la corrupción .\n\nAMLO\n1. Asegura AMLO que en campaña todo será amor y paz , que los otros candidatos se ahorren sus provocaciones .\n377. “ Y tiene que ver con la alianza de el PRI y de el PAN , no hay que olvidar que los de el PRI , los de el PAN , los de el PRIAN se pusieron de acuerdo para nombrar a los consejeros de el INE , que tampoco son blancas palomas y también se pusieron de acuerdo para nombrar a los magistrados de el Tribunal_Electoral , yo lo denuncié en su momento ” , comentó .\n753. “ Antes en las elecciones pasadas no podíamos defender nos frente_a los ataques a la guerra sucia , a las calumnias , porque nos cercaban , nos daban espacios o actuaban de manera tendenciosa en los medios convencionales , pero en esta elección la diferencia la están marcando las redes sociales , ya no pueden ” , expresó .\n1129. En otro orden de ideas , informó que si hoy fuesen las elecciones ganaría con 25 puntos de ventaja , es bastante el número de mexicanos que lo apoyan , pero hay quienes crearán de manera artificial la polarizar el voto para las elecciones de el 1_de_julio , pero no es lo mismo el 2018 a el 2006 .\n1505. “ Cuánto fue el dinero de el presupuesto que se utilizó para imponer la mal llamada reforma educativa , es una investigación periodística de primer orden , salió hace dos_días en un periódico de que el secretario de Educación ( Aurelio_Nuño ) que se gastó 2_mil_millones_de_pesos , pero eso no es todo , se trata de un año ” , expuso .\n1881. En Autlán_de_Navarro , Jalisco , indicó que se tiene que respetar a los ganadores de la contienda electoral en relación a la Presidencia_de_la_República , pero también a quienes vayan como diputados locales y federales , así_como senadores , presidentes municipales .\n2257. Expresó que se mejorarán los servicios de salud como el ISSSTE y el Seguro , se aumentará a el doble la pensión para adultos mayores será de mil_500_pesos mensuales y para todos , y habrá apoyo para los discapacitados pobres de el país .\n2633. Adelanta AMLO que planteará a Trump un acuerdo de cooperación entre EU , Canadá , México y Centroamérica .\n3009. Indicó que ahora se compra la mitad de la luz que se consume en México a empresas extrajeras que tienen subsidio de 50_mil_millones_de_pesos a el año .\n\n"
    }
   ],
   "source": [
    "sentences = get_sentences(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenvuelvo los grupos de enunciados en un único arreglo con todos los enunciados de todos los candidatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(chain(*sentences.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso los tokens a minúsculas para reducir el tamaño del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "El corpus consta de 6889 enunciados.\n"
    }
   ],
   "source": [
    "corpus = [[w.lower() for w in sent] for sent in corpus]\n",
    "print(f'El corpus consta de {len(corpus)} enunciados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono k oraciones de prueba para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "meade expuso que mientras los migrantes mexicanos contribuyen a la prosperidad y desarrollo de la sociedad y economía estadounidenses , las armas y el dinero en efectivo que ingresan desde ee.uu. a méxico caen en_manos_de delincuentes , lo que alimenta la inseguridad y la violencia en nuestro país .\npidió tener confianza , porque no les va a fallar , no va a quedar les mal , ni se decepcionará , tiene tres principios que lo guían : no mentir , no robar y no traicionar a el pueblo de méxico y se llevará_a_cabo la cuarta transformación de la vida pública de méxico , sin violencia , de manera pacífica .\npidió que el voto sea parejo por los candidatos de la coalición “ juntos_haremos_historia ” , porque ahora se repite mucho esa cantaleta de : “ vota por el peje , pero para la gobernatura no votes por lomelí o no votes por maría_antonia_cárdenas_para_el_senado ” .\ncomenta que espera que los otros candidatos se tranquilicen , que se serenen , es normal , están a el final de la campaña , todos quieren redoblar el esfuerzo y avanzar .\ny creo que la conclusión es que no ha fallado la gente , han fallado los gobiernos , porque hemos tenido gobiernos profundamente corruptos y gobiernos profundamente ineficaces y eso es lo que yo he querido cambiar ” .\naseguró que cumplirá con todos los compromisos limpiará de corrupción a el gobierno , aplicará un plan de austeridad republicana , se contarán los privilegios de los altos funcionarios públicos , y con los ahorros que se obtengan se impulsarán las actividades productivas , habrá trabajo y bienestar para los mexicanos , se acabará el bandidaje oficial , “ vamos aponer orden ” .\neste programa , detalló , consiste en acciones concretas para la primera infancia , desde la gestación y hasta los primeros dos años de vida , con acciones de estimulación temprana , principalmente a_través_de el cariño y cuidado de los padres , una adecuada alimentación y un sistema de salud para el correcto crecimiento de las niñas y de los niños .\nsostuvo que habrá apoyo federal para el gobierno de la ciudad_de_méxico para que se le dé un apoyo de mil_500_pesos mensuales para adultos mayores de la capital a_partir_de los 65 años y será universal .\na la pregunta de los reporteros sobre cuál sería el mensaje que le daría a los empresarios , el candidato presidencial respondió que se apoyarán con créditos sin intereses a los que tienen talleres , comercios , producción de textiles y calzado , porque el propósito es que la ropa y el calzado que usen se produzca en méxico , genera empleos para los mexicanos .\n“ nosotros no vamos a seguir el ejemplo de ningún gobierno extranjero ” , “ ni chavismo ni trumpismo , sí mexicanismo y vamos juntos a hacer historia ” , finalizó .\n"
    }
   ],
   "source": [
    "k = 1000\n",
    "sentences = random.sample(corpus, k=k)\n",
    "print('\\n'.join([' '.join(sent) for sent in sentences[::k//10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuento los tokens en todas las oraciones e imprimo los 40 más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('toma', 1), ('recreativas', 1), ('diversas', 1), ('deportivos', 1), ('llaman', 1), ('layda_sansores', 1), ('acusación', 1), ('conservadurismo', 1), ('apoyado', 1), ('desesperación', 1), ('enfilando', 1), ('amparo', 1), ('medrando', 1), ('enemigos', 1), ('bloqueó', 1), ('crea', 1), ('preocupó', 1), ('hacendado', 1), ('apóstol', 1), ('admirador', 1), ('kilo_de_ayuda', 1), ('asociación', 1), ('centros_para_el_desarrollo_infantil_temprano', 1), ('acambay', 1), ('bebé', 1), ('pacto_por_la_primera_infancia', 1), ('radical', 1), ('candidata', 1), ('deficiencias', 1), ('involucrada', 1), ('mención', 1), ('obran', 1), ('desviar', 1), ('pretende', 1), ('infundadas', 1), ('predicar', 1), ('artes', 1), ('disfrute', 1), ('formarán_parte', 1)]\n"
    }
   ],
   "source": [
    "freq = sum([Counter(sent) for sent in sentences], Counter())\n",
    "print(freq.most_common()[:-40:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5102"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "num_tokens = len(freq.keys())\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego un diccionario para pasar de palabra a índice numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_index = {\n",
    "    w : ix\n",
    "    for ix, (w, freq) in enumerate(freq.most_common())\n",
    "    if freq > 1 # No toma en cuenta los hapax\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "ixBOS = num_tokens + 1\n",
    "ixEOS = num_tokens + 2\n",
    "ixUNK = num_tokens + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_index[BOS] = ixBOS\n",
    "w_to_index[EOS] = ixEOS\n",
    "w_to_index[UNK] = ixUNK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo el diccionario inverso, para convertir de índices a palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_w = [ w for w, ix in w_to_index.items() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests = random.sample(w_to_index.keys(), k=10)\n",
    "# for w in tests:\n",
    "#     ix = w_to_index[w]\n",
    "#     assert index_to_w[ix] == w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexo todo el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_to_index_unk(w):\n",
    "    \"\"\"\n",
    "    Le asigna el token UNK a palabras que no aparezcan en el corpus\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return w_to_index[w] \n",
    "    except KeyError:\n",
    "        return ixUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ejemplos X\n[array([  66,  260,    3,  715,    9,  595,   86, 5105,    5,    4, 1100,\n          7,  108,    1,    4,  218,    7,  236, 5105,    0,   18,  596,\n          7,    2,  123,    8,  294,    3, 5105,  109, 1511,    5,   24,\n       5105, 5105,  716,    0,   20,    3, 5105,    4,  237,    7,    4,\n         87,    8,   88,   28]), array([   5,   78,    1,    9,  104,   54,   47,    4, 5105,  133,   89,\n         12, 1101,    8,   50,  326,    0,   39,   90,  597,   35,   14,\n        867,    3,   43,   22, 1512,   11,    3, 1513,    0,   12,  868,\n        869,  598,  717,    0,   10, 5105,   22, 5105,    0,   20, 5105,\n          7,   41,    3, 1102, 1514,   15]), array([  10,  168,    1,    3,    8,   73,    2,   27,   12,  510,    9,\n        870,    8,  599, 1515,    0,   12,  510,    2,  600,    0,   96,\n          2, 5105,    0,   12,   10, 1516, 5105,    0,   37,    5,  601,\n          0,    5, 1517,   20,    3,   10,  718,    0,   12,   10, 5105,\n          8,   20,    3,   16, 5105,   89,  602,    0,   12,   61, 1103,\n          7,  391,   20,    3,   10, 5105,  443, 5105,  295,    1,  123,\n          0,   23,   10, 1104,    2, 1105,    1,  356,    3,   43,    8,\n          2,   27])]\nEjemplos Y\n[array([ 260,    3,  715,    9,  595,   86, 5105,    5,    4, 1100,    7,\n        108,    1,    4,  218,    7,  236, 5105,    0,   18,  596,    7,\n          2,  123,    8,  294,    3, 5105,  109, 1511,    5,   24, 5105,\n       5105,  716,    0,   20,    3, 5105,    4,  237,    7,    4,   87,\n          8,   88,   28,    6]), array([  78,    1,    9,  104,   54,   47,    4, 5105,  133,   89,   12,\n       1101,    8,   50,  326,    0,   39,   90,  597,   35,   14,  867,\n          3,   43,   22, 1512,   11,    3, 1513,    0,   12,  868,  869,\n        598,  717,    0,   10, 5105,   22, 5105,    0,   20, 5105,    7,\n         41,    3, 1102, 1514,   15,    6]), array([ 168,    1,    3,    8,   73,    2,   27,   12,  510,    9,  870,\n          8,  599, 1515,    0,   12,  510,    2,  600,    0,   96,    2,\n       5105,    0,   12,   10, 1516, 5105,    0,   37,    5,  601,    0,\n          5, 1517,   20,    3,   10,  718,    0,   12,   10, 5105,    8,\n         20,    3,   16, 5105,   89,  602,    0,   12,   61, 1103,    7,\n        391,   20,    3,   10, 5105,  443, 5105,  295,    1,  123,    0,\n         23,   10, 1104,    2, 1105,    1,  356,    3,   43,    8,    2,\n         27,    6])]\n"
    }
   ],
   "source": [
    "sentences_ix = [\n",
    "    [ w_to_index_unk(w) for w in sent ] \n",
    "    for sent in sentences\n",
    "]\n",
    "\n",
    "X = [ np.asarray(sent[:-1]) for sent in sentences_ix ]\n",
    "Y = [ np.asarray(sent[1:]) for sent in sentences_ix ] \n",
    "\n",
    "print('Ejemplos X')\n",
    "print(X[:3])\n",
    "print('Ejemplos Y')\n",
    "print(Y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mando los vectores de entrada y salida a tensores en gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pytorch_tensor(list_of_lists):\n",
    "    return [\n",
    "        torch.from_numpy(l).float().to(device)\n",
    "        for l in list_of_lists\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = to_pytorch_tensor(X_train)\n",
    "X_test = to_pytorch_tensor(X_test)\n",
    "Y_train = to_pytorch_tensor(Y_train)\n",
    "Y_test = to_pytorch_tensor(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "### 1. Capa de embedding\n",
    "\n",
    "### 2. Capa oculta\n",
    "\n",
    "### 3. Capa de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino las variables para la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión de entrada (one-hot), tamaño del vocabulario\n",
    "D_in = len(index_to_w)\n",
    "\n",
    "# Dimensión de la capa de embedding\n",
    "D_emb = 32\n",
    "\n",
    "# Dimensión de la capa lstm\n",
    "D_lstm = 16\n",
    "\n",
    "# Dimensión de la capa de salida\n",
    "D_out = D_in\n",
    "\n",
    "# Épocas de entrenamiento\n",
    "num_epochs = 10\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.001\n",
    "\n",
    "# Betas para Adam\n",
    "beta1 = 0.0002\n",
    "beta2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Model, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb),\n",
    "            nn.LSTMCell(input_size=D_emb, hidden_size=D_lstm, bias=True),\n",
    "            nn.Linear(in_features=D_lstm, out_features=D_out, bias=True),\n",
    "            nn.Softmax(dim=D_out)\n",
    "        )\n",
    "\n",
    "    def forward(self):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Model(\n  (main): Sequential(\n    (0): Embedding(2278, 32)\n    (1): LSTMCell(32, 16)\n    (2): Linear(in_features=16, out_features=2278, bias=True)\n    (3): Softmax(dim=2278)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "model = Model(ngpu).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de pesos\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Embedding') != -1:\n",
    "        # Regularizo los pesos\n",
    "        n = m.num_embeddings\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        n = m.in_features\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('LSTMCell') != -1:\n",
    "        n = m.input_size\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight_ih.data.uniform_(-y, y)\n",
    "        m.weight_hh.data.uniform_(-y, y)\n",
    "        m.bias_ih.data.fill_(0)\n",
    "        m.bias_hh.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Model(\n  (main): Sequential(\n    (0): Embedding(2278, 32)\n    (1): LSTMCell(32, 16)\n    (2): Linear(in_features=16, out_features=2278, bias=True)\n    (3): Softmax(dim=2278)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropía cruzada como optmizador y SGD como optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "forward() takes 1 positional argument but 2 were given",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-11f5646fbbe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# Forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Step 4. Compute the loss, gradients, and update the parameters by\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\aypit-2020-2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "        # Limpiamos gradientes acumulados\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        pred = model(x)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch:>12} Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitaypit20202conda2eb9642ad5e346f38de29b14c14576bc",
   "display_name": "Python 3.7.7 64-bit ('aypit-2020-2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}