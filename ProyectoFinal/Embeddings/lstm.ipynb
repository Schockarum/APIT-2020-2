{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings con LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import random\n",
    "# from itertools import chain\n",
    "# from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\\helpers\n"
     ]
    }
   ],
   "source": [
    "cd ../helpers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boletines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\\Embeddings\n"
     ]
    }
   ],
   "source": [
    "cd ../Embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  42069\n"
     ]
    }
   ],
   "source": [
    "# Número de GPUs disponibles. Usar 0 para modo CPU.\n",
    "ngpu = 1\n",
    "\n",
    "# Semilla a usar en los generadores de números aleatorios\n",
    "SEED = 42069\n",
    "# SEED = random.randint(1, 10000) # En caso de requerir más resultados\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\"Random Seed: \", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono el tipo de dispositivo a utilizar (gpu o cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decide si queremos correr en gpu o cpu\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = open('./../mongo_uri.txt', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_sentences = boletines.sentences(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso los tokens a minúsculas para reducir el tamaño del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El corpus consta de 6564 enunciados.\n",
      "Tamaño mínimo: 5 tokens.\n",
      "Tamaño máximo: 129 tokens.\n",
      "Tamaño promedio: 38.22943327239488 tokens.\n",
      "Desviación estándar: 18.479413427637674 tokens.\n"
     ]
    }
   ],
   "source": [
    "sentences = [[w.lower() for w in sent] for sent in dict_sentences['sentences']]\n",
    "print(f'El corpus consta de {dict_sentences[\"count\"]} enunciados.')\n",
    "print(f'Tamaño mínimo: {dict_sentences[\"min\"]} tokens.')\n",
    "print(f'Tamaño máximo: {dict_sentences[\"max\"]} tokens.')\n",
    "print(f'Tamaño promedio: {dict_sentences[\"avg\"]} tokens.')\n",
    "print(f'Desviación estándar: {dict_sentences[\"std\"]} tokens.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimo algunas oraciones de muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.- asegura amlo que en campaña todo será amor y paz , que los otros candidatos se ahorren sus provocaciones .\n",
      "\n",
      "2.- a la pregunta de los reporteros de cómo es su preparación en el debate , lópez_obrador respondió que aquí se está preparando a el conceder una entrevista a los representantes de los medios de comunicación .\n",
      "\n",
      "3.- frente_a quienes plantean dividir a la nación , el candidato de el pri , pvem y nueva_alianza prometió unidad y seguridad jurídica para que se invierta y se generen empleos .\n",
      "\n",
      "4.- a la pregunta de los reporteros qué si tiene algún comentario sobre lo que dijo meade de acusar de secuestradora a nestora_salgado , lópez_obrador mencionó que se dicen muchas mentiras y “ ella fue calumniada , ella es una dirigente social , está luchando , porque haya paz y tranquilidad ” .\n",
      "\n",
      "5.- así lo señaló arturo_zamora , líder de la confederación_nacional_de_organizaciones_populares , tras apuntar que el encuentro entre abanderados presidenciales , a celebrar se en mérida , dejará en claro que meade es el candidato más preparado para conducir a el país .\n",
      "\n",
      "6.- deseó que le fuera bien a la selección mexicana de futbol , porque suceda lo que suceda : “ méxico va a ganar ” y señaló que a el acabar con la corrupción y con los privilegios habrá presupuesto para financiar el desarrollo y que haya progreso con justicia .\n"
     ]
    }
   ],
   "source": [
    "step = max(dict_sentences[\"count\"]//5, 1)\n",
    "print('\\n\\n'.join(\n",
    "    [ f\"{i+1}.- {' '.join(sent)}\" for i, sent in enumerate(sentences[::step]) ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuento los tokens en todas las oraciones e imprimo algunos de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "freq = sum([Counter(sent) for sent in sentences], Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tipos: 13454\n",
      "[(',', 19107), ('mujer', 46), ('grave', 21), ('mala', 13), ('llegará', 9), ('profesional', 7), ('respecto_de', 5), ('pozos', 4), ('nuño', 4), ('íntegro', 3), ('liberal', 3), ('desempeño', 2), ('presidencia_de_la_república_actúa', 2), ('martha_tagle', 2), ('protestar', 2), ('secundamos', 1), ('aéreas', 1), ('engañe', 1), ('mediático', 1), ('pondremos', 1), ('coordinaciones', 1), ('lamentaron', 1), ('esforzaron', 1), ('construí', 1), ('innovaciones', 1), ('decepcionarán', 1)]\n"
     ]
    }
   ],
   "source": [
    "n_tipos = len(freq.keys())\n",
    "print(f'Número de tipos: {n_tipos}')\n",
    "print(freq.most_common()[::max(n_tipos//25, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego un diccionario para pasar de palabra a índice numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_ix = {\n",
    "    w : ix\n",
    "    for ix, (w, freq) in enumerate(freq.most_common())\n",
    "    if freq > 1 # No toma en cuenta los hapax\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7609"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(w_to_ix)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego símbolos de inicio y fin de cadena, así como el token <UNK\\> para palabras no vistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "ixBOS = vocab_size\n",
    "ixEOS = vocab_size + 1\n",
    "ixUNK = vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_ix[BOS] = ixBOS\n",
    "w_to_ix[EOS] = ixEOS\n",
    "w_to_ix[UNK] = ixUNK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo el nuevo tamaño del vocabulario después de agregar 3 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7612"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(w_to_ix)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo el diccionario inverso, para convertir de índices a palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_w = [ w for w, ix in w_to_ix.items() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexo todo el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_to_index_unk(w):\n",
    "    \"\"\"\n",
    "    Le asigna el token UNK a palabras que no aparezcan en el corpus\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return w_to_ix[w] \n",
    "    except KeyError:\n",
    "        return ixUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos X\n",
      "[array([7609,  634,  258,    2,    8,   54,   57,   68,  381,    7,   65,\n",
      "          0,    2,    9,  213,  110,   10, 5497,   35, 4308,    6]), array([7609, 1089,   42,  242,    2,   11, 1818,  103,    3,   84,    1,\n",
      "        163,  108,   10, 3600,   16,  288, 1405,    6]), array([7609,  667, 2261,    2,  316,   10, 2496,    7,   20,  298, 1264,\n",
      "          8,  792,    6])]\n",
      "Ejemplos Y\n",
      "[array([ 634,  258,    2,    8,   54,   57,   68,  381,    7,   65,    0,\n",
      "          2,    9,  213,  110,   10, 5497,   35, 4308,    6, 7610]), array([1089,   42,  242,    2,   11, 1818,  103,    3,   84,    1,  163,\n",
      "        108,   10, 3600,   16,  288, 1405,    6, 7610]), array([ 667, 2261,    2,  316,   10, 2496,    7,   20,  298, 1264,    8,\n",
      "        792,    6, 7610])]\n"
     ]
    }
   ],
   "source": [
    "sentences_ix = [\n",
    "    # Le agrego el inicio y fin de caracter a los enunciados\n",
    "    [ixBOS] + [ w_to_index_unk(w) for w in sent ] + [ixEOS] \n",
    "    for sent in sentences\n",
    "]\n",
    "\n",
    "X = [ np.asarray(sent[:-1]) for sent in sentences_ix ]\n",
    "Y = [ np.asarray(sent[1:]) for sent in sentences_ix ] \n",
    "\n",
    "print('Ejemplos X')\n",
    "print(X[:3])\n",
    "print('Ejemplos Y')\n",
    "print(Y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4594\n",
      "1970\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mando los vectores de entrada y salida a tensores en gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pytorch_tensor(list_of_lists):\n",
    "    return [\n",
    "        torch.from_numpy(l).long().to(device)\n",
    "        for l in list_of_lists\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = to_pytorch_tensor(X_train)\n",
    "Y_train = to_pytorch_tensor(Y_train)\n",
    "\n",
    "X_test = to_pytorch_tensor(X_test)\n",
    "Y_test = to_pytorch_tensor(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "### 1. Capa de embedding\n",
    "\n",
    "### 2. Capa oculta\n",
    "\n",
    "### 3. Capa de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino las variables para la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión de entrada (one-hot), tamaño del vocabulario\n",
    "D_in = vocab_size\n",
    "\n",
    "# Dimensión de la capa de embedding\n",
    "D_emb = 64 # 32\n",
    "\n",
    "# Dimensión de la capa lstm\n",
    "D_lstm = 32 # 16\n",
    "\n",
    "# Dimensión de la capa de salida\n",
    "D_out = D_in\n",
    "\n",
    "# Épocas de entrenamiento\n",
    "num_epochs = 350\n",
    "\n",
    "# Learning rate\n",
    "lr =  0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ngpu, D_in, D_emb, D_lstm, D_out):\n",
    "        super(Model, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.embedding = nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb)#, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=D_emb, hidden_size=D_lstm) #, bias=True)#, batch_first=True)\n",
    "        self.linear = nn.Linear(in_features=D_lstm, out_features=D_out) #, bias=True)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        T = len(sentence)\n",
    "        embeddings = self.embedding(sentence).view(T, 1, -1)\n",
    "        lstm_out, (ht, ct) = self.lstm(embeddings)\n",
    "        lstm_out = lstm_out.view(T, -1)\n",
    "        preact_out = self.linear(lstm_out).view(T, -1)\n",
    "        \n",
    "        return F.log_softmax(preact_out, dim=1)\n",
    "    \n",
    "    def pred(self, sentence):\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(sentence)\n",
    "            pred = torch.argmax(out, dim=1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(7612, 64)\n",
       "  (lstm): LSTM(64, 32)\n",
       "  (linear): Linear(in_features=32, out_features=7612, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(ngpu, D_in, D_emb, D_lstm, D_out).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verisimilitud logarítmica negativa como función de coste y SGD como optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "criterion.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf42765199b4666a2d5d5b2eccf316a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=350.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Coste después de 1 épocas: 27134.14709877968\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    epoch_loss = 0\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "        if len(x) == 0:\n",
    "            tqdm.write('Sentencia vacía')\n",
    "            continue\n",
    "        # Limpiamos gradientes acumulados\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        out = model(x)\n",
    "     \n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    if epoch%20 == 0:\n",
    "        tqdm.write(f'Coste después de {epoch+1} épocas: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ix_sentence(sentence):\n",
    "    print(' '.join(index_to_w[ix] for ix in sentence.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    for sentence, y in zip(X_test[:10], Y_test[:10]):\n",
    "        print('===================================================')\n",
    "        print('- Probando enunciado:')\n",
    "        print_ix_sentence(sentence)\n",
    "        print()\n",
    "        \n",
    "        print('- Real:')\n",
    "        print_ix_sentence(y)\n",
    "        print()\n",
    "        \n",
    "        prediccion = model.pred(sentence)\n",
    "        print('- Predicción:')\n",
    "        print_ix_sentence(prediccion)\n",
    "        print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'model-freeling-emb_{D_emb}-lstm_{D_lstm}_seed_{SEED}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_labels_gte5.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(index_to_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = list(model.named_parameters())\n",
    "# list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embs = model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npembs = embs.detach().to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npembs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npembs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npembs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(npembs[:,0], npembs[:,1])\n",
    "# r=0\n",
    "# for label,x,y in zip(index_to_w, npembs[:,0], npembs[:,1]):\n",
    "#     plt.annotate(label, xy=(x,y), xytext=(-1,1), textcoords='offset points', ha='center', va='bottom')\n",
    "#     r+=1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('aypit-2020-2': conda)",
   "language": "python",
   "name": "python37764bitaypit20202conda2eb9642ad5e346f38de29b14c14576bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
