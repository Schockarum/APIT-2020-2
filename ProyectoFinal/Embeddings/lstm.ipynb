{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings con LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import random\n",
    "from itertools import chain\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\n"
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.boletines import get_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\Usuario.000\\Documents\\Facultad\\Git\\2020-2\\APIT-2020-2\\ProyectoFinal\\Embeddings\n"
    }
   ],
   "source": [
    "cd Embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Random Seed:  42069\n"
    }
   ],
   "source": [
    "# Número de GPUs disponibles. Usar 0 para modo CPU.\n",
    "ngpu = 1\n",
    "\n",
    "# Semilla a usar en los generadores de números aleatorios\n",
    "SEED = 42069\n",
    "# SEED = random.randint(1, 10000) # En caso de requerir más resultados\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\"Random Seed: \", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono el tipo de dispositivo a utilizar (gpu o cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Decide si queremos correr en gpu o cpu\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = open('./../mongo_uri.txt', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AMLO\n1. Asegura AMLO que en campaña todo será amor y paz , que los otros candidatos se ahorren sus provocaciones .\n377. “ Y tiene que ver con la alianza de el PRI y de el PAN , no hay que olvidar que los de el PRI , los de el PAN , los de el PRIAN se pusieron de acuerdo para nombrar a los consejeros de el INE , que tampoco son blancas palomas y también se pusieron de acuerdo para nombrar a los magistrados de el Tribunal_Electoral , yo lo denuncié en su momento ” , comentó .\n753. “ Antes en las elecciones pasadas no podíamos defender nos frente_a los ataques a la guerra sucia , a las calumnias , porque nos cercaban , nos daban espacios o actuaban de manera tendenciosa en los medios convencionales , pero en esta elección la diferencia la están marcando las redes sociales , ya no pueden ” , expresó .\n1129. En otro orden de ideas , informó que si hoy fuesen las elecciones ganaría con 25 puntos de ventaja , es bastante el número de mexicanos que lo apoyan , pero hay quienes crearán de manera artificial la polarizar el voto para las elecciones de el 1_de_julio , pero no es lo mismo el 2018 a el 2006 .\n1505. “ Cuánto fue el dinero de el presupuesto que se utilizó para imponer la mal llamada reforma educativa , es una investigación periodística de primer orden , salió hace dos_días en un periódico de que el secretario de Educación ( Aurelio_Nuño ) que se gastó 2_mil_millones_de_pesos , pero eso no es todo , se trata de un año ” , expuso .\n1881. En Autlán_de_Navarro , Jalisco , indicó que se tiene que respetar a los ganadores de la contienda electoral en relación a la Presidencia_de_la_República , pero también a quienes vayan como diputados locales y federales , así_como senadores , presidentes municipales .\n2257. Expresó que se mejorarán los servicios de salud como el ISSSTE y el Seguro , se aumentará a el doble la pensión para adultos mayores será de mil_500_pesos mensuales y para todos , y habrá apoyo para los discapacitados pobres de el país .\n2633. Adelanta AMLO que planteará a Trump un acuerdo de cooperación entre EU , Canadá , México y Centroamérica .\n3009. Indicó que ahora se compra la mitad de la luz que se consume en México a empresas extrajeras que tienen subsidio de 50_mil_millones_de_pesos a el año .\n\nRAC\n1. De_la_mano_de jóvenes innovadores , comienza Ricardo_Anaya el camino hacia la Presidencia_de_la_República .\n377. Finalmente , sostuvo que López_Obrador es “ el espanta inversiones ” , porque su actitud provoca que estas se vayan , lo cual es muy delicado , porque cuando no hay inversión no crece la economía y no se generan empleos .\n753. “ Sí , necesitamos cambiar ciertas piezas de el modelo económico , estamos en un momento crítico , donde tenemos que elegir entre volver a el pasado a_través_de un cómic o construir un futuro más incluyente , igualitario , a_partir_de propuestas series , razonadas , en donde los cómo están claros y los para qué , son parte principal de lo que se pretende hacer ” , enfatizó a el contrastar con la propuesta que hace López_Obrador .\n1129. Yo quiero paz para Jalisco , yo quiero paz para México , y esa paz la voy a construir con las mujeres , esa paz la vamos a construir todos juntos ” , enfatizó .\n\nJAMK\n1. José_Antonio_Meade fue recibido en Culiacán por cientos de simpatizantes sinaloenses .\n377. El aspirante presidencial se comprometió a mejorar la infraestructura carretera e hidráulica en la entidad .\n753. “ Si tuviera que resumir en una idea el país por el que apuesto para los próximos seis años , lo resumiría en tres palabras : un México líder ” , indicó .\n1129. De_acuerdo_con diversas estimaciones , las armas en poder de la delincuencia organizada en México podrían alcanzar el número de 1.5 millones de piezas , esto es 3 veces el arsenal con el que cuenta , por_ejemplo , el ejército de Guatemala .\n1505. Expresó que , sin_ninguna_duda y con toda certeza , logrará la victoria el 1_de_julio .\n1881. Dijo que con Mikel_Arriola va por una Ciudad_de_México donde abramos la llave y salga agua , que no sea extorsionada por delegados que condicionan el agua a la militancia política , una ciudad que no tandee el agua , donde el derecho a el agua sea vigente , se eviten las fugas y se evite la corrupción .\n\n"
    }
   ],
   "source": [
    "sentences = get_sentences(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenvuelvo los grupos de enunciados en un único arreglo con todos los enunciados de todos los candidatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(chain(*sentences.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso los tokens a minúsculas para reducir el tamaño del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "El corpus consta de 6889 enunciados.\n"
    }
   ],
   "source": [
    "corpus = [[w.lower() for w in sent] for sent in corpus]\n",
    "print(f'El corpus consta de {len(corpus)} enunciados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono k oraciones de prueba para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "y se comprometió a regresar como presidente electo para traer el plan de desarrollo para uruapan para decir cuánto se invertirá en la región y regresará cada seis meses para evaluar el plan .\npreviamente , lópez_obrador denunció que están haciendo llamadas telefónicas a_el_por_mayor a ciudadanos para difamar lo y describió que las llamadas provienen de número telefónicos de el país y de el extranjero , es un bombardeo de llamadas .\nindicó que la zona franca se mantuvo en toda la línea fronteriza en la época de porfirio_díaz , después en la revolución_mexicana , hasta que llegó carlos_salinas_de_gortari que acabó con el apoyo en la frontera .\nlamentó la violencia que vive el país y confió en que a_pesar_de la situación , la gente saldrá a votar , porque tiene mucho interés en participar el 1_de_julio .\na su salida , entrevistado por los medios de comunicación , reiteró su llamado a el voto útil , invitando a las y los ciudadanos a participar libremente en el proyecto de coalición , y cerrando la puerta a los pactos cupulares .\nmeade asumió siete compromisos puntuales para combatir la inseguridad y ofreció una nación libre de violencia , corrupción y marginación .\nadelantó que regresará como presidente electo para traer el plan de desarrollo e informará cuánto invertirá en actividades productivas , infraestructura y desarrollo social por pueblo , localidad , municipios y la región , se le dará seguimiento , se evaluará entre todos .\nhay gente buena , militante o no militante de partidos políticos .\nlópez_obrador respondió que el caso de mireles ya se ve en el tribunal_electoral , mientras tanto el doctor es “ nuestro candidato ” .\nandrés_manuel_lópez_obrador pidió el voto parejo por los candidatos de la coalición “ juntos haremos historia ” .\n“ estamos viviendo un momento estelar en la historia de méxico y ustedes son protagonistas fundamentales , yo confío mucho en ustedes , porque son gente consciente , mujeres y hombres con convicción , les mando un abrazo fuerte ” , finalizó .\n"
    }
   ],
   "source": [
    "k = 6889\n",
    "sentences = random.sample(corpus, k=k)\n",
    "print('\\n'.join([' '.join(sent) for sent in sentences[::k//10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuento los tokens en todas las oraciones e imprimo los 40 más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = sum([Counter(sent) for sent in sentences], Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'num_tipos' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-059fcc98ae78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_tipos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Número de tipos: {num_tipos}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_tipos\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_tipos' is not defined"
     ]
    }
   ],
   "source": [
    "n_tipos = len(freq.keys())\n",
    "print(f'Número de tipos: {num_tipos}')\n",
    "print(freq.most_common()[::n_tipos//25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego un diccionario para pasar de palabra a índice numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_index = {\n",
    "    w : ix\n",
    "    for ix, (w, freq) in enumerate(freq.most_common())\n",
    "    if freq > 1 # No toma en cuenta los hapax\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7793"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "vocab_size = len(w_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "ixBOS = vocab_size\n",
    "ixEOS = vocab_size + 1\n",
    "ixUNK = vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_to_index[BOS] = ixBOS\n",
    "w_to_index[EOS] = ixEOS\n",
    "w_to_index[UNK] = ixUNK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo el nuevo tamaño del vocabulario después de agregar 3 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7796"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "vocab_size = len(w_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo el diccionario inverso, para convertir de índices a palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_w = [ w for w, ix in w_to_index.items() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexo todo el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_to_index_unk(w):\n",
    "    \"\"\"\n",
    "    Le asigna el token UNK a palabras que no aparezcan en el corpus\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return w_to_index[w] \n",
    "    except KeyError:\n",
    "        return ixUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ejemplos X\n[array([7793,    7,   10,  178,    5,  742,   30,   61,  487,   12,  892,\n          3,  206,    1,   98,   12, 2316,   12,  128,  983,   10, 1239,\n          8,    4,  341,    7,  763,  182,  409,  764,   12, 3203,    3,\n        206,    6]), array([7793, 1525,    2,   29, 1998,    4, 2317,    1,    4, 4420,    5,\n          3,  546,    7,    1,    3, 5634,    5,    3,  546,    1, 4421,\n        179,    0,    2,   11,   17,    1, 5635,    0,  230,    1, 5636,\n          6]), array([7793,  154,   17,    4, 2844,    2,   40,    0,    2, 5637,   34,\n        455,    2,   36,    5, 1035,    5,  590,   15,    0,   31, 3696,\n          6])]\nEjemplos Y\n[array([   7,   10,  178,    5,  742,   30,   61,  487,   12,  892,    3,\n        206,    1,   98,   12, 2316,   12,  128,  983,   10, 1239,    8,\n          4,  341,    7,  763,  182,  409,  764,   12, 3203,    3,  206,\n          6, 7794]), array([1525,    2,   29, 1998,    4, 2317,    1,    4, 4420,    5,    3,\n        546,    7,    1,    3, 5634,    5,    3,  546,    1, 4421,  179,\n          0,    2,   11,   17,    1, 5635,    0,  230,    1, 5636,    6,\n       7794]), array([ 154,   17,    4, 2844,    2,   40,    0,    2, 5637,   34,  455,\n          2,   36,    5, 1035,    5,  590,   15,    0,   31, 3696,    6,\n       7794])]\n"
    }
   ],
   "source": [
    "sentences_ix = [\n",
    "    # Le agrego el inicio y fin de caracter a los enunciados\n",
    "    [ixBOS] + [ w_to_index_unk(w) for w in sent ] + [ixEOS] \n",
    "    for sent in sentences\n",
    "]\n",
    "\n",
    "X = [ np.asarray(sent[:-1]) for sent in sentences_ix ]\n",
    "Y = [ np.asarray(sent[1:]) for sent in sentences_ix ] \n",
    "\n",
    "print('Ejemplos X')\n",
    "print(X[:3])\n",
    "print('Ejemplos Y')\n",
    "print(Y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4822\n2067\n"
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mando los vectores de entrada y salida a tensores en gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pytorch_tensor(list_of_lists):\n",
    "    return [\n",
    "        torch.from_numpy(l).long().to(device)\n",
    "        for l in list_of_lists\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = to_pytorch_tensor(X_train)\n",
    "Y_train = to_pytorch_tensor(Y_train)\n",
    "\n",
    "X_test = to_pytorch_tensor(X_test)\n",
    "Y_test = to_pytorch_tensor(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "### 1. Capa de embedding\n",
    "\n",
    "### 2. Capa oculta\n",
    "\n",
    "### 3. Capa de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino las variables para la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión de entrada (one-hot), tamaño del vocabulario\n",
    "D_in = vocab_size\n",
    "\n",
    "# Dimensión de la capa de embedding\n",
    "D_emb = 2 # 32\n",
    "\n",
    "# Dimensión de la capa lstm\n",
    "D_lstm = 4 # 16\n",
    "\n",
    "# Dimensión de la capa de salida\n",
    "D_out = D_in\n",
    "\n",
    "# Épocas de entrenamiento\n",
    "num_epochs = 10\n",
    "\n",
    "# Betas para Adam\n",
    "beta1 = 0.0001\n",
    "beta2 = 0.99\n",
    "\n",
    "# Learning rate\n",
    "lr =  0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ngpu, D_in, D_emb, D_lstm, D_out):\n",
    "        super(Model, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.embedding = nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb)#, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=D_emb, hidden_size=D_lstm, bias=True)#, batch_first=True)\n",
    "        # self.out_layer = nn.Sequential(\n",
    "        #     nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb, padding_idx=0),\n",
    "        #     nn.LSTM(input_size=D_emb, hidden_size=D_lstm, bias=True, batch_first=True),\n",
    "        #     nn.Linear(in_features=D_lstm, out_features=D_out, bias=True),\n",
    "        #     nn.Softmax(dim=D_out)\n",
    "        # )\n",
    "        self.linear = nn.Linear(in_features=D_lstm, out_features=D_out, bias=True)\n",
    "        # self.out_layer = nn.Softmax(dim=1)\n",
    "        # self.out_layer = nn.Sequential(\n",
    "        #     nn.Linear(in_features=D_lstm, out_features=D_out, bias=True),\n",
    "        #     nn.Softmax(dim=1)\n",
    "        # )\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        T = len(sentence)\n",
    "        # print(sentence)\n",
    "        # print(T)\n",
    "\n",
    "        embeddings = self.embedding(sentence).view(T, 1, -1)\n",
    "        # print('Embeddings')\n",
    "        # print(embeddings)\n",
    "\n",
    "        lstm_out, (ht, ct) = self.lstm(embeddings)\n",
    "        lstm_out = lstm_out.view(T, -1)\n",
    "        # print('LSTM_out')\n",
    "        # print(lstm_out)\n",
    "\n",
    "        preact_out = self.linear(lstm_out).view(T, -1)\n",
    "        # print('Preact out')\n",
    "        # print(preact_out)\n",
    "\n",
    "        return F.log_softmax(preact_out, dim=1)\n",
    "        # return self.out_layer(preact_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Model(\n  (embedding): Embedding(7796, 2)\n  (lstm): LSTM(2, 4)\n  (linear): Linear(in_features=4, out_features=7796, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "model = Model(ngpu, D_in, D_emb, D_lstm, D_out).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de pesos\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Embedding') != -1:\n",
    "#         # Regularizo los pesos\n",
    "#         n = m.num_embeddings\n",
    "#         y = 1.0/np.sqrt(n)\n",
    "#         m.weight.data.uniform_(-y, y)\n",
    "#     elif classname.find('Linear') != -1:\n",
    "#         n = m.in_features\n",
    "#         y = 1.0/np.sqrt(n)\n",
    "#         m.weight.data.uniform_(-y, y)\n",
    "#         m.bias.data.fill_(0)\n",
    "#     elif classname.find('LSTM') != -1:\n",
    "#         n = m.input_size\n",
    "#         y = 1.0/np.sqrt(n)\n",
    "#         m.weight_ih_l0.data.uniform_(-y, y)\n",
    "#         m.weight_hh_l0.data.uniform_(-y, y)\n",
    "#         m.bias_ih_l0.data.fill_(0)\n",
    "#         m.bias_hh_l0.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropía cruzada como optmizador y SGD como optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Coste después de 1 épocas: 39828.01940870285\nCoste después de 2 épocas: 33264.7314453125\nCoste después de 3 épocas: 31796.366305589676\nCoste después de 4 épocas: 31189.253276586533\nCoste después de 5 épocas: 30796.07231426239\nCoste después de 6 épocas: 30489.32657933235\nCoste después de 7 épocas: 30223.72301888466\nCoste después de 8 épocas: 29971.639236211777\nCoste después de 9 épocas: 29699.824879407883\nCoste después de 10 épocas: 29454.79591369629\nWall time: 4min 23s\n"
    }
   ],
   "source": [
    "%%time\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "    # for x, y in tqdm(zip(X_train, Y_train)):\n",
    "        if len(x) == 0:\n",
    "            tqdm.write('Sentencia vacía')\n",
    "            continue\n",
    "        # Limpiamos gradientes acumulados\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        # print(x)\n",
    "        pred = model(x)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        # break\n",
    "    # tqdm.write(f'Epoch: {epoch:>12} Loss: {loss}')\n",
    "    # break\n",
    "    print(f'Coste después de {epoch+1} épocas: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ix_sentence(sentence):\n",
    "    print(' '.join(index_to_w[ix] for ix in sentence.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===================================================\n- Probando enunciado:\n<BOS> a el dejar en claro que los mexicanos no se quedarán <UNK> de <UNK> , ricardo_anaya advirtió que este <UNK> requiere que el estado_mexicano tome cartas en el asunto para defender los intereses nacionales y los derechos de los mexicanos que viven en los estados_unidos .\n\n- Predicción:\n, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , <EOS>\n- Real:\na el dejar en claro que los mexicanos no se quedarán <UNK> de <UNK> , ricardo_anaya advirtió que este <UNK> requiere que el estado_mexicano tome cartas en el asunto para defender los intereses nacionales y los derechos de los mexicanos que viven en los estados_unidos . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> otra acción que realizará , detalló , es que se terminarán todos los lujos en el gobierno federal , además se <UNK> a el avión presidencial que costó 7_mil_500_millones_de_pesos , se venderá la flotilla de aviones y helicópteros de el gobierno .\n\n- Predicción:\n, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , <EOS> , , , <EOS> , , , <EOS>\n- Real:\notra acción que realizará , detalló , es que se terminarán todos los lujos en el gobierno federal , además se <UNK> a el avión presidencial que costó 7_mil_500_millones_de_pesos , se venderá la flotilla de aviones y helicópteros de el gobierno . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> para apoyar el ingreso familiar y hacer más <UNK> los negocios que están en la franja fronteriza , dijo que el gobierno de el frente bajará el iva a la mitad , de el 16 a el ocho por ciento , a_el_tiempo_que implementará estímulos para que se <UNK> el precio de la gasolina con el de los estados_unidos .\n\n- Predicción:\n, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , <EOS>\n- Real:\npara apoyar el ingreso familiar y hacer más <UNK> los negocios que están en la franja fronteriza , dijo que el gobierno de el frente bajará el iva a la mitad , de el 16 a el ocho por ciento , a_el_tiempo_que implementará estímulos para que se <UNK> el precio de la gasolina con el de los estados_unidos . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> siempre “ vamos a dar el beneficio de la duda cuando se trata de la democracia ” .\n\n- Predicción:\n, , <EOS> <EOS> , , , , , , , , , , , , , , <EOS>\n- Real:\nsiempre “ vamos a dar el beneficio de la duda cuando se trata de la democracia ” . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> señaló que se tiene que votar por la transformación de méxico , no se trata de votar por un candidato o por un partido , lo más importante es votar por el programa de transformación de el país .\n\n- Predicción:\n, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , <EOS>\n- Real:\nseñaló que se tiene que votar por la transformación de méxico , no se trata de votar por un candidato o por un partido , lo más importante es votar por el programa de transformación de el país . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> esta acción , detalló , implica elevar la norma mexicana en igualdad laboral y no discriminación a la categoría de norma oficial .\n\n- Predicción:\n, , , , , , , , , , , , , , , , , , , , , , , <EOS>\n- Real:\nesta acción , detalló , implica elevar la norma mexicana en igualdad laboral y no discriminación a la categoría de norma oficial . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> el candidato presidencial de todos_por_méxico afirma que el relanzamiento de la campaña y el buen debate que dio ayer en tijuana lo llevarán a el triunfo .\n\n- Predicción:\n, , , , , , <EOS> , , , , , , , , , <EOS> , , , , , , , , , , <EOS>\n- Real:\nel candidato presidencial de todos_por_méxico afirma que el relanzamiento de la campaña y el buen debate que dio ayer en tijuana lo llevarán a el triunfo . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> mencionó que habrá <UNK> a la transformación de la vida pública de el país y citó un dicho tabasqueño de la <UNK> : “ <UNK> que come <UNK> ni_que le <UNK> el <UNK> ” , van a querer estar buscando la manera de seguir robando .\n\n- Predicción:\n, , , , , , , , , , , , , , , , , , , , , , , , <EOS> , , <EOS> , , , , , , , , , , , , , , , , , , <EOS>\n- Real:\nmencionó que habrá <UNK> a la transformación de la vida pública de el país y citó un dicho tabasqueño de la <UNK> : “ <UNK> que come <UNK> ni_que le <UNK> el <UNK> ” , van a querer estar buscando la manera de seguir robando . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> reitera llamado a el voto útil y dice no a los acuerdos cupulares .\n\n- Predicción:\n, , , , , , , , , , , , , , <EOS>\n- Real:\nreitera llamado a el voto útil y dice no a los acuerdos cupulares . <EOS>\n\n\n===================================================\n- Probando enunciado:\n<BOS> el abanderado de la coalición todos_por_méxico dijo que faltan dos_terceras_partes de la campaña y convencerá a el electorado .\n\n- Predicción:\n, , , , , , , , , , , , , , , , , , , <EOS>\n- Real:\nel abanderado de la coalición todos_por_méxico dijo que faltan dos_terceras_partes de la campaña y convencerá a el electorado . <EOS>\n\n\n"
    }
   ],
   "source": [
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    for sentence, y in zip(X_test[:10], Y_test[:10]):\n",
    "        print('===================================================')\n",
    "        print('- Probando enunciado:')\n",
    "        print_ix_sentence(sentence)\n",
    "        print()\n",
    "\n",
    "        out = model(sentence)\n",
    "        prediccion = torch.argmax(out, dim=1)\n",
    "        print('- Predicción:')\n",
    "        print_ix_sentence(prediccion)\n",
    "        print\n",
    "        print('- Real:')\n",
    "        print_ix_sentence(y)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('embedding.weight',\n Parameter containing:\n tensor([[ 1.6694, -1.6333],\n         [ 0.5349,  0.8884],\n         [ 0.8397, -2.0565],\n         ...,\n         [-1.9192,  0.0346],\n         [-0.0697,  1.1478],\n         [-0.6999, -0.4746]], device='cuda:0', requires_grad=True))"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "list(model.named_parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitaypit20202conda2eb9642ad5e346f38de29b14c14576bc",
   "display_name": "Python 3.7.7 64-bit ('aypit-2020-2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}