{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torchvision\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngpu = 1\n",
    "# Decide si queremos correr en gpu o cpu\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', 'de', 'que', 'la', 'a', 'el']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_w = open('word_labels_corenlp.txt', 'r', encoding='utf-8').read().splitlines()\n",
    "ix_to_w[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7474"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_to_ix = {w: ix for ix, w in enumerate(ix_to_w)}\n",
    "vocab_size = len(w_to_ix)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ngpu, D_in, D_emb, D_lstm, D_out):\n",
    "        super(Model, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.embedding = nn.Embedding(num_embeddings=D_in, embedding_dim=D_emb)#, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=D_emb, hidden_size=D_lstm) #, bias=True)#, batch_first=True)\n",
    "        self.linear = nn.Linear(in_features=D_lstm, out_features=D_out) #, bias=True)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        T = len(sentence)\n",
    "\n",
    "        embeddings = self.embedding(sentence).view(T, 1, -1)\n",
    "\n",
    "        lstm_out, (ht, ct) = self.lstm(embeddings)\n",
    "        lstm_out = lstm_out.view(T, -1)\n",
    "\n",
    "        preact_out = self.linear(lstm_out).view(T, -1)\n",
    "\n",
    "        return F.log_softmax(preact_out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión de entrada (one-hot), tamaño del vocabulario\n",
    "D_in = vocab_size\n",
    "\n",
    "# Dimensión de la capa de embedding\n",
    "D_emb = 64 # 32\n",
    "\n",
    "# Dimensión de la capa lstm\n",
    "D_lstm = 32 # 16\n",
    "\n",
    "# Dimensión de la capa de salida\n",
    "D_out = D_in\n",
    "\n",
    "# Modelo por cargar\n",
    "model_state = 'modelsaves/modelv2-corenlp-emb_64-lstm_32-seed_42069-epochs_299-best-val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(7474, 64)\n",
       "  (lstm): LSTM(64, 32)\n",
       "  (linear): Linear(in_features=32, out_features=7474, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(ngpu, D_in, D_emb, D_lstm, D_out)\n",
    "model.load_state_dict(torch.load(model_state))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<BOS>'\n",
    "EOS = '<EOS>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "ixBOS = w_to_ix[BOS]\n",
    "ixEOS = w_to_ix[EOS]\n",
    "ixUNK = w_to_ix[UNK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = [\n",
    "    'andrés manuel lópez obrador',\n",
    "    'lópez obrador',\n",
    "    'ricardo anaya',\n",
    "    'anaya',\n",
    "    'josé antonio meade',\n",
    "    'meade',\n",
    "    'el candidato',\n",
    "    '\"'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7471, 64, 56, 29, 30],\n",
       " [7471, 29, 30],\n",
       " [7471, 49, 41],\n",
       " [7471, 41],\n",
       " [7471, 48, 50, 34],\n",
       " [7471, 34],\n",
       " [7471, 5, 26],\n",
       " [7471, 10]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sents_ix = [\n",
    "    [ixBOS]+[w_to_ix[w] for w in sent.split()] \n",
    "    for sent in test_sents\n",
    "]\n",
    "test_sents_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pytorch_tensor(list_of_lists):\n",
    "    return [\n",
    "        torch.LongTensor(l).to(device)\n",
    "        for l in list_of_lists\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([7471,   64,   56,   29,   30], device='cuda:0'),\n",
       " tensor([7471,   29,   30], device='cuda:0'),\n",
       " tensor([7471,   49,   41], device='cuda:0'),\n",
       " tensor([7471,   41], device='cuda:0'),\n",
       " tensor([7471,   48,   50,   34], device='cuda:0'),\n",
       " tensor([7471,   34], device='cuda:0'),\n",
       " tensor([7471,    5,   26], device='cuda:0'),\n",
       " tensor([7471,   10], device='cuda:0')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = to_pytorch_tensor(test_sents_ix)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ix_sentence(sentence, end='\\n'):\n",
    "    print(' '.join(ix_to_w[ix] for ix in sentence.data), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_sent(sentence, limit = 47, choose_max=True):\n",
    "    if len(sentence) == 0:\n",
    "        sentence = torch.LongTensor([ixBOS]).to(device)\n",
    "    torchEOS = torch.LongTensor([ixEOS]).to(device)\n",
    "    i = 0\n",
    "    prediccion = sentence[-1:]\n",
    "    while not torch.eq(prediccion, torchEOS):\n",
    "        out = model(sentence)\n",
    "        if choose_max:\n",
    "            prediccion = torch.argmax(out[-1:], dim=1)\n",
    "        else:\n",
    "            prediccion = torch.multinomial(torch.exp(out[-1]), 1)\n",
    "#         print_ix_sentence(prediccion, end=' ') # Imprimo el siguiente caracter\n",
    "        sentence = torch.cat((sentence, prediccion), dim=0) # Genero siguiente cadena\n",
    "        i+=1\n",
    "        if i>limit:\n",
    "            break\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> andrés manuel lópez obrador\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> andrés manuel lópez obrador anunció que se <UNK> la elección del país , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> lópez obrador\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> lópez obrador expresó que se <UNK> la corrupción , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> ricardo anaya\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> ricardo anaya cortés , el candidato de la coalición todos por méxico al frente a la presidencia de la república , josé antonio meade , dijo que se <UNK> la corrupción , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> anaya\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> anaya es que se <UNK> la corrupción , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> josé antonio meade\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> josé antonio meade dijo que se <UNK> la elección del país , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> meade\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> meade afirmó que se <UNK> la elección del país , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> el candidato\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> el candidato de la coalición todos por méxico al frente a la presidencia de la república , josé antonio meade , dijo que se <UNK> la corrupción , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> \"\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> \" no se <UNK> la corrupción , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no se <UNK> el dinero de la gente , porque no\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for sentence in X_test[:10]:\n",
    "        print('===================================================')\n",
    "        print('- Probando enunciado:')\n",
    "        print_ix_sentence(sentence)\n",
    "        print()\n",
    "        \n",
    "        print('- Enunciado generado:')\n",
    "        gen_sentence = generar_sent(sentence, limit=47, choose_max=True)\n",
    "        print_ix_sentence(gen_sentence)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> andrés manuel lópez obrador\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> andrés manuel lópez obrador llamó a medios de campaña en <UNK> , los jóvenes , en el ine ciro días estado de desarrollo y encabezará zepeda https: mitin para desarrollar el movimiento <UNK> . <EOS>\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> lópez obrador\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> lópez obrador respondió para <UNK> la familia . <EOS>\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> ricardo anaya\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> ricardo anaya dijo que se han dedicado a lo que mueven el problema de bienes de la asamblea de la semilla histórica . <EOS>\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> anaya\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> anaya no a la presidencia de méxico contará a la entidad , el abanderado de los partidos revolucionario institucional ( pri ) , verde ecologista de méxico ( pvem ) y nueva alianza anunció que llega ahora no se necesitan por qué se dieron los sueldos de los estados\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> josé antonio meade\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> josé antonio meade invitó a generar profunda al populismo de eu y a los productores del país , contrato y jiutepec , tabasco , ahí se apoyará a niños del presupuesto público para aumentar fundamentales . <EOS>\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> meade\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> meade subrayó que hoy <UNK> a través del país : mante quién es como el palacio municipal gonzález . <EOS>\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> el candidato\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> el candidato la coalición todos por méxico a la presidencia de méxico manifestó que en su caso de acuerdo como capital en la elección , el pri es fundamental que se <UNK> un desplegado . <EOS>\n",
      "\n",
      "\n",
      "===================================================\n",
      "- Probando enunciado:\n",
      "<BOS> \"\n",
      "\n",
      "- Enunciado generado:\n",
      "<BOS> \" a los mexicanos es agropecuaria de legalidad . <EOS>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for sentence in X_test[:10]:\n",
    "        print('===================================================')\n",
    "        print('- Probando enunciado:')\n",
    "        print_ix_sentence(sentence)\n",
    "        print()\n",
    "        \n",
    "        print('- Enunciado generado:')\n",
    "        gen_sentence = generar_sent(sentence, limit=47, choose_max=False)\n",
    "        print_ix_sentence(gen_sentence)\n",
    "        print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('aypit-2020-2': conda)",
   "language": "python",
   "name": "python37764bitaypit20202conda2eb9642ad5e346f38de29b14c14576bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
