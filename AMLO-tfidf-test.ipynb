{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import nltk.data\n",
    "from itertools import chain\n",
    "from functools import reduce\n",
    "import re\n",
    "from math import log\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('Data/boletines-AMLO.json', dtype=\"dict\", encoding=\"utf-8\")\n",
    "boletines = data['boletines']\n",
    "corpus = [boletin[\"contenido\"] for boletin in boletines]\n",
    "counter_boletines = [Counter(contenido) for contenido in corpus_tokenizado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokenizado = [re.findall('[a-zA-zñáéíóúüÁÉÍÓÚÜÑ]+', contenido.lower()) for contenido in corpus if len(contenido)>2]\n",
    "ch = chain(*corpus_tokenizado)\n",
    "todos_los_tokens = list(ch)\n",
    "df_corpus = pd.DataFrame(todos_los_tokens)\n",
    "df_corpus.to_csv('Data/pln_corpus_amlo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('stop-words-spanish.txt', mode='r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "corpus_tokenizado = [[w for w in doc if not (w in stopwords)] for doc in corpus_tokenizado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(x, k=25):\n",
    "    return ((x + 1)*k)/(x+k)\n",
    "\n",
    "def tf(documento, func=bm25):\n",
    "    c = Counter(documento)\n",
    "    return {\n",
    "        termino : bm25(cuenta) for (termino, cuenta) in c.items()\n",
    "    }\n",
    "\n",
    "def idf(palabra, documentos):\n",
    "    return log(\n",
    "        len(documentos) / \n",
    "        (1+reduce(lambda cuenta, documento : cuenta + (1 if (palabra in documento) else 0), documentos, 0))\n",
    "    )\n",
    "\n",
    "def tfidf(tf : dict, idfs : dict):\n",
    "    return {\n",
    "            palabra: idfs[palabra]*tf_value\n",
    "            for (palabra, tf_value) in tf.items()\n",
    "    }\n",
    "\n",
    "def obtener_keywords(tfidfs, num_keywords=5):\n",
    "    keywords = []\n",
    "    for tfidf_n in tfidfs:\n",
    "        keywords_n = sorted(tfidf_n.items() ,  key=lambda x: x[1], reverse=True)[:num_keywords]\n",
    "        keywords.append([keyword[0] for keyword in keywords_n])\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuenta_total_palabras = reduce((lambda x, y: x + y), counter_boletines)\n",
    "palabras = [palabra for (palabra, cuenta) in cuenta_total_palabras.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = {\n",
    "    palabra: idf(palabra, corpus_tokenizado) for palabra in palabras\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = [tf(corpus_tokenizado[1]), tf(corpus_tokenizado[23])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfs = [\n",
    "    {\n",
    "        palabra: idfs[palabra]*tf\n",
    "        for (palabra, tf) in tf_n.items()\n",
    "    }\n",
    "    for tf_n in tfs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['catarina',\n",
       "  'técnicos',\n",
       "  'apodaca',\n",
       "  'mesa',\n",
       "  'santa',\n",
       "  'tlc',\n",
       "  'aeropuerto',\n",
       "  'viable',\n",
       "  'léon',\n",
       "  'dosis',\n",
       "  'alternativo',\n",
       "  'sostienen',\n",
       "  'hundimiento',\n",
       "  'n',\n",
       "  'tendrían'],\n",
       " ['moral',\n",
       "  'populismo',\n",
       "  'redes',\n",
       "  'corral',\n",
       "  'sucia',\n",
       "  'ético',\n",
       "  'chihuahua',\n",
       "  'mensajes',\n",
       "  'seguidores',\n",
       "  'contracampaña',\n",
       "  'imperativo',\n",
       "  'dominando',\n",
       "  'quisieron',\n",
       "  'documental',\n",
       "  'roberto']]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = obtener_keywords(tfidfs, 15)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
